<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on Numerical optimization</title><link>http://ammarmian.github.io/numerical_optimization/</link><description>Recent content in Introduction on Numerical optimization</description><generator>Hugo</generator><language>fr</language><atom:link href="http://ammarmian.github.io/numerical_optimization/index.xml" rel="self" type="application/rss+xml"/><item><title>1. Machine learning fundamentals</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/fundamentals/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/fundamentals/</guid><description>&lt;h1 id="machine-learning-fundamentals-through-optimization">
 Machine learning fundamentals through optimization
 &lt;a class="anchor" href="#machine-learning-fundamentals-through-optimization">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: This lecture bridges our study of numerical optimization with machine learning, showing how the optimization techniques we&amp;rsquo;ve developed provide the mathematical foundation for learning from data.&lt;/p>
&lt;/blockquote>
&lt;h2 id="machine-learning-vs-traditional-programming">
 Machine learning vs traditional programming
 &lt;a class="anchor" href="#machine-learning-vs-traditional-programming">#&lt;/a>
&lt;/h2>
&lt;h3 id="traditional-programming-paradigm">
 Traditional programming paradigm
 &lt;a class="anchor" href="#traditional-programming-paradigm">#&lt;/a>
&lt;/h3>
&lt;p>In traditional programming, we explicitly encode rules and logic to transform inputs into outputs. The paradigm follows a straightforward path: we receive input data, apply hand-crafted rules, and produce an output. This approach has served us well for many deterministic problems, but it encounters significant limitations when dealing with complex pattern recognition tasks.&lt;/p></description></item><item><title>1. Optimization problems</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/optimization_problems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/optimization_problems/</guid><description>&lt;h1 id="optimization-problems">
 Optimization problems
 &lt;a class="anchor" href="#optimization-problems">#&lt;/a>
&lt;/h1>
&lt;h2 id="unconstrained-vs-constrained">
 Unconstrained vs constrained
 &lt;a class="anchor" href="#unconstrained-vs-constrained">#&lt;/a>
&lt;/h2>
&lt;p>What we are interested in these lectures is to solve problems of the form :&lt;/p>
&lt;p>\begin{equation}
\underset{\mathbf{x}\in\mathbb{R}^d}{\operatorname{(arg)min}} f(\mathbf{x}),
\label{eq: optim general unconstrained}
\end{equation}
where $\mathbf{x}\in\mathbb{R}^d$ and $f:\mathcal{D}_f \mapsto \mathbb{R} $ is a scalar-valued function with domain $\mathcal{D}_f$. Under this formulation, the problem is said to be an &lt;strong>unconstrained optimization&lt;/strong> problem.&lt;/p>
&lt;p>If additionally, we add a set of equalities constraints functions:
$$
\{h_i : \mathbb{R}^d \mapsto \mathbb{R} \, /\, 1 \leq i \leq N \}
$$
and inequalities constraints functions:
$$
\{g_j : \mathbb{R}^d \mapsto \mathbb{R} \, /\, 1 \leq j \leq M \}
$$
and define the set $\mathcal{S} = \{\mathbf{x} \in \mathbb{R}^d \,/\, \forall\,(i, j),\, h_i(\mathbf{x})=0,\, g_j(\mathbf{x})\leq 0\}$ and want to solve:
\begin{equation}
\underset{\mathbf{x}\in\mathcal{S}}{\operatorname{(arg)min}} f(\mathbf{x}),
\label{eq: optim general constrained}
\end{equation}
then the problem is said to be a &lt;strong>constrained optimization&lt;/strong> problem.&lt;/p></description></item><item><title>1. Unconstrained optimization : Second-order</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/unconstrained_newton/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/unconstrained_newton/</guid><description>&lt;h1 id="unconstrained-optimization----second-order-methods">
 Unconstrained optimization - Second-order methods
 &lt;a class="anchor" href="#unconstrained-optimization----second-order-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>We have seen in the previous chapter that first-order methods, such as steepest descent, are often used to find a local minimum of a function $f(\mathbf{x})$. However, these methods can be slow to converge, especially when the function has ill-conditioned Hessian or when the initial guess is far from the solution. Second-order methods, which use information about the curvature of the function, can provide faster convergence rates.&lt;/p></description></item><item><title>Linear Algebra</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/linear_algebra/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/linear_algebra/</guid><description>&lt;h1 id="fundamentals-of-linear-algebra">
 Fundamentals of Linear Algebra
 &lt;a class="anchor" href="#fundamentals-of-linear-algebra">#&lt;/a>
&lt;/h1>
&lt;h2 id="1---introduction">
 1 - Introduction
 &lt;a class="anchor" href="#1---introduction">#&lt;/a>
&lt;/h2>
&lt;blockquote>
&lt;p>Linear algebra is one of the foundational branches of mathematics, with applications spanning from engineering and computer science to economics and physics. This document is extracted from the textbook &lt;strong>Matrix Differential Calculus with Applications in Statistics and Econometrics&lt;/strong> from Jan R. Magnus; Heinz Neudecker, adapting the notations to the ones used in the lectures.&lt;/p>
&lt;/blockquote>
&lt;p>In this chapter, we summarize some of the well-known definitions and theorems of matrix algebra. Most of the theorems will be proved.&lt;/p></description></item><item><title>2. Classification and support vector machines</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/svm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/svm/</guid><description>&lt;h1 id="classification-and-support-vector-machines">
 Classification and support vector machines
 &lt;a class="anchor" href="#classification-and-support-vector-machines">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: This lecture extends our optimization framework to classification problems, introducing the perceptron algorithm and support vector machines (SVMs). We&amp;rsquo;ll see how the constrained optimization techniques from previous lectures lead to powerful classification methods.&lt;/p>
&lt;/blockquote>
&lt;h2 id="classification-problems-in-depth">
 Classification problems in depth
 &lt;a class="anchor" href="#classification-problems-in-depth">#&lt;/a>
&lt;/h2>
&lt;h3 id="types-of-classification">
 Types of classification
 &lt;a class="anchor" href="#types-of-classification">#&lt;/a>
&lt;/h3>
&lt;p>In our previous lecture, we introduced binary classification through logistic regression. Let&amp;rsquo;s now formalize the broader classification framework and understand how different formulations connect to optimization problems.&lt;/p></description></item><item><title>2. Proximal methods</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/proximal_methods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/proximal_methods/</guid><description>&lt;h1 id="proximal-methods">
 Proximal methods
 &lt;a class="anchor" href="#proximal-methods">#&lt;/a>
&lt;/h1>
&lt;p>We refer the reader to the monograph by &lt;a href="https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf">Parikh and Boyd (2014)&lt;/a> for a comprehensive overview of proximal methods.&lt;/p></description></item><item><title>2. Unconstrained optimization : basics</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/</guid><description>&lt;h1 id="unconstrained-optimization---basics">
 Unconstrained optimization - basics
 &lt;a class="anchor" href="#unconstrained-optimization---basics">#&lt;/a>
&lt;/h1>
&lt;p>We hereby consider problems without any constraints on the set of admissible solutions, i.e we aim to solve:
$$
\underset{\mathbf{x}\in\mathbb{R}^d}{\operatorname{argmin}} f(\mathbf{x}).
$$&lt;/p>
&lt;p>Let us try to characterizes the nature of the solutions under this setup.&lt;/p>
&lt;h2 id="what-is-a-solution-">
 What is a solution ?
 &lt;a class="anchor" href="#what-is-a-solution-">#&lt;/a>
&lt;/h2>








&lt;figure id="figure-%!s(int=2)-1">&lt;img src="%20../../../../../../tikZ/local_global_minima/main.svg"
 alt="Local vs global" width="600px">
 &lt;figcaption>
 &lt;p>
 &lt;strong>Figure 2.1: &lt;/strong>Local and global minimum can coexist.&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>Generally, we would be happiest if we found a global minimizer of $f$ , a point where the
function attains its least value. A formal definition is :&lt;/p></description></item><item><title>Differentiation</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/differentiation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/differentiation/</guid><description>&lt;h1 id="differentiation-in-multiple-dimensions">
 Differentiation in Multiple Dimensions
 &lt;a class="anchor" href="#differentiation-in-multiple-dimensions">#&lt;/a>
&lt;/h1>
&lt;h2 id="1---introduction">
 1 - Introduction
 &lt;a class="anchor" href="#1---introduction">#&lt;/a>
&lt;/h2>
&lt;blockquote>
&lt;p>Differentiation provides the mathematical framework for understanding how functions change locally. While single-variable calculus introduces derivatives, most applications require working with functions of multiple variables. This chapter extends differentiation concepts to multivariate and matrix-valued functions, building the tools needed for optimization and analysis in higher dimensions.&lt;/p>
&lt;/blockquote>
&lt;h2 id="2---monovariate-reminders">
 2 - Monovariate Reminders
 &lt;a class="anchor" href="#2---monovariate-reminders">#&lt;/a>
&lt;/h2>
&lt;h3 id="derivative-of-a-function">
 Derivative of a Function
 &lt;a class="anchor" href="#derivative-of-a-function">#&lt;/a>
&lt;/h3>










&lt;div id="derivative_definition" class="theorem-box">
 &lt;p class="theorem-title">&lt;strong>Definition 0.1 (Derivative)&lt;/strong>&lt;/p></description></item><item><title>Introduction</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/1_introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/1_introduction/</guid><description>&lt;h1 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h1>
&lt;h2 id="notations">
 Notations
 &lt;a class="anchor" href="#notations">#&lt;/a>
&lt;/h2>
&lt;p>Let us start by defining the notation used troughout all the lectures and practical labs.&lt;/p>
&lt;h3 id="basic-notation">
 Basic Notation
 &lt;a class="anchor" href="#basic-notation">#&lt;/a>
&lt;/h3>
&lt;p>Scalars are represented by italic letters (e.g., $x$, $y$, $\lambda$). Vectors are denoted by bold lowercase letters (e.g., $\mathbf{v}$, $\mathbf{x}$), while matrices are represented by bold uppercase letters (e.g., $\mathbf{A}$, $\mathbf{B}$). The dimensionality of a vector $\mathbf{v} \in \mathbb{R}^n$ indicates it contains $n$ elements, and similarly, a matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$ has $m$ rows and $n$ columns.&lt;/p></description></item><item><title>3. Convexity theory</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/convexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/convexity/</guid><description>&lt;h1 id="convexity-theory">
 Convexity theory
 &lt;a class="anchor" href="#convexity-theory">#&lt;/a>
&lt;/h1>
&lt;p>Convexity is a powerful property of functions and sets that simplifies the analysis of optimization problems and the characterization of global minimizers. In this chapter, we will explore the concepts of convex sets, convex functions, and their implications for unconstrained optimization.&lt;/p>
&lt;h2 id="convex-sets">
 Convex sets
 &lt;a class="anchor" href="#convex-sets">#&lt;/a>
&lt;/h2>
&lt;p>Let us first start by defining the convexity of a given set $\mathcal{S}\subset\mathbb{R}^d$:&lt;/p>










&lt;div id="convex_set" class="theorem-box">
 &lt;p class="theorem-title">&lt;strong>Definition 3.1 (Convex set)&lt;/strong>&lt;/p>
 &lt;div class="theorem-content">
 Let $\mathcal{S}\subset\mathbb{R}^d$ be a set. The set $\mathcal{S}$ is convex if, for any two points $\mathbf{x}, \mathbf{y} \in \mathcal{S}$, the line segment that connects them is also contained in $\mathcal{S}$, that is,
\begin{equation}
\mathbf{x}, \mathbf{y} \in \mathcal{S} \implies \lambda \mathbf{x} + (1-\lambda) \mathbf{y} \in \mathcal{S}, \quad \forall \lambda \in [0, 1].
\label{eq:convex_set}
\end{equation}
 &lt;/div>
&lt;/div>


&lt;div class="center-container">
 &lt;div class="center-content">
 








&lt;figure id="convex_set">&lt;img src="%20../../../../../../tikZ/convex_set/main.svg"
 alt="Zig zag" width="400px">
 &lt;figcaption>
 &lt;p>
 &lt;strong>Figure 3.1: &lt;/strong>Convex set&lt;/p></description></item><item><title>3. Neural Networks</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/neural_networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/neural_networks/</guid><description>&lt;h1 id="neural-networks">
 Neural Networks
 &lt;a class="anchor" href="#neural-networks">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>4. Modern trends</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/modern/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/modern/</guid><description>&lt;h1 id="modern-trends">
 Modern trends
 &lt;a class="anchor" href="#modern-trends">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>4. Unconstrained optimization : linesearch</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/</guid><description>&lt;h1 id="unconstrained-optimization---linesearch-methods">
 Unconstrained optimization - Linesearch methods
 &lt;a class="anchor" href="#unconstrained-optimization---linesearch-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>All algorithms for unconstrained minimization require the user to supply a starting point, which we usually denote by $\mathbf{x}_0$. The user with knowledge about the application and the data set may be in a good position to choose $\mathbf{x}_0$ to be a reasonable estimate of the solution. Otherwise, the starting point must be chosen in some arbitrary manner.&lt;/p></description></item><item><title>5. Constrained optimization - Introduction</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/</guid><description>&lt;h1 id="constrained-optimization-methods">
 Constrained optimization methods
 &lt;a class="anchor" href="#constrained-optimization-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>The second part of this lecture is about minimizing functions subject to constraints on the variables. A general formulation for these problems is&lt;/p>
&lt;p>$$
\min_{\mathbf{x} \in \mathrm{R}^{n}} f(\mathbf{x}) \quad \text { subject to } \quad \begin{cases}c_{i}(\mathbf{x})=0, &amp;amp; i \in \mathcal{E}, \\ c_{i}(\mathbf{x}) \geq 0, &amp;amp; i \in \mathcal{I},\end{cases}
$$&lt;/p></description></item><item><title>5b. Constrained optimization - Projected Gradient Descent</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_projected/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_projected/</guid><description>&lt;h1 id="understanding-saddle-points-in-constrained-optimization-from-kkt-conditions-to-projected-gradient-methods">
 Understanding Saddle Points in Constrained Optimization: From KKT Conditions to Projected Gradient Methods
 &lt;a class="anchor" href="#understanding-saddle-points-in-constrained-optimization-from-kkt-conditions-to-projected-gradient-methods">#&lt;/a>
&lt;/h1>
&lt;p>When we first encounter the Karush-Kuhn-Tucker (KKT) conditions in constrained optimization, they often appear as a collection of mathematical requirements that characterize optimal solutions. However, these conditions actually emerge from a deeper geometric structure that reveals why constrained optimization problems possess fundamentally different mathematical properties than their unconstrained counterparts. This exploration will guide you through understanding how constraint conflicts create saddle point structures in the Lagrangian, and how this mathematical insight leads naturally to practical algorithms.&lt;/p></description></item><item><title>6. Constrained optimization - Linear programming</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimization_linear/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimization_linear/</guid><description>&lt;h2 id="linear-programming">
 Linear programming
 &lt;a class="anchor" href="#linear-programming">#&lt;/a>
&lt;/h2>
&lt;p>Linear programs have a linear objective function and linear constraints, which may include both equalities and inequalities. The feasible set is a polytope, that is, a convex, connected set with flat, polygonal faces. The contours of the objective function are planar. The solution in this case is unique-a single vertex. A simple reorientation of the polytope or the objective gradient $\mathbf{c}$ could, however, make the solution nonunique; the optimal value $\mathbf{c}^{\mathrm{T}} \mathbf{x}$ could be the same on an entire edge. In higher dimensions, the set of optimal points can be a single vertex, an edge or face, or even the entire feasible set!&lt;/p></description></item><item><title>I - Linear Regression models</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/linear_regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/linear_regression/</guid><description>&lt;h1 id="linear-regression-models">
 Linear Regression models
 &lt;a class="anchor" href="#linear-regression-models">#&lt;/a>
&lt;/h1>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;p>In this lab session, we will explore the fundamental concepts of numerical optimization through the lens of linear regression. We&amp;rsquo;ll begin with the simplest case and gradually build up to more complex scenarios, comparing analytical solutions with numerical methods at each step.&lt;/p>
&lt;p>Linear regression is perhaps the most fundamental problem in machine learning and statistics. While it has a closed-form solution, implementing numerical optimization methods for this problem provides excellent intuition for more complex optimization scenarios where analytical solutions don&amp;rsquo;t exist.&lt;/p></description></item><item><title>II - MNIST and Fashion-MNIST Classification</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/mnist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/mnist/</guid><description>&lt;h1 id="mnist-and-fashion-mnist-classification">
 MNIST and Fashion-MNIST Classification
 &lt;a class="anchor" href="#mnist-and-fashion-mnist-classification">#&lt;/a>
&lt;/h1>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;p>In this lab session, we explore handwritten digit recognition using the MNIST dataset, progressing from classical machine learning approaches to modern deep learning techniques. We then apply transfer learning to the more challenging Fashion-MNIST dataset. This progression mirrors the historical development of the field while providing hands-on experience with key optimization concepts.&lt;/p>
&lt;p>The session is divided into three parts:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Part I&lt;/strong>: Classical approaches using Multi-Layer Perceptrons (MLP) and Support Vector Machines (SVM)&lt;/li>
&lt;li>&lt;strong>Part II&lt;/strong>: Deep learning with Convolutional Neural Networks (CNN)&lt;/li>
&lt;li>&lt;strong>Part III&lt;/strong>: Transfer learning applied to Fashion-MNIST&lt;/li>
&lt;/ul>
&lt;h2 id="learning-objectives">
 Learning objectives
 &lt;a class="anchor" href="#learning-objectives">#&lt;/a>
&lt;/h2>
&lt;p>By the end of this session, you should be able to:&lt;/p></description></item><item><title>II - Remote Sensing Project</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/remote_sensing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/remote_sensing/</guid><description>&lt;h1 id="solving-inverse-problems-in-remote-sensing">
 Solving Inverse Problems in Remote Sensing
 &lt;a class="anchor" href="#solving-inverse-problems-in-remote-sensing">#&lt;/a>
&lt;/h1>
&lt;h2 id="readme">
 README
 &lt;a class="anchor" href="#readme">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>To get all the material for the labs, clone the following git repo : &lt;a href="https://github.com/y-mhiri/hsi_unmixing_lab">https://github.com/y-mhiri/hsi_unmixing_lab&lt;/a>.&lt;/li>
&lt;li>You can follow this lab in multiple level of difficulty&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>&lt;strong>The easiest way&lt;/strong> : Answer only the theoretical question and follow the notebooks in &lt;code>notebooks/&lt;/code> to do the programming&lt;/li>
&lt;li>&lt;strong>Intermediary level&lt;/strong> : Implement your own code to answer the lab questions using the helper functions you&amp;rsquo;ll find in &lt;code>src/&lt;/code>&lt;/li>
&lt;li>&lt;strong>Expert level&lt;/strong> : I guess you don&amp;rsquo;t even need to clone the git repo&amp;hellip;&lt;/li>
&lt;/ol>
&lt;p>If anything don&amp;rsquo;t hesitate to reach me at &lt;code>yassine.mhiri@univ-smb.fr&lt;/code>.&lt;/p></description></item><item><title>Lab environment</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/environment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/environment/</guid><description>&lt;h1 id="lab-environment-setup">
 Lab Environment Setup
 &lt;a class="anchor" href="#lab-environment-setup">#&lt;/a>
&lt;/h1>
&lt;p>Welcome to the numerical optimization course! This page will guide you through setting up a modern, efficient Python environment using &lt;strong>uv&lt;/strong>.&lt;/p>
&lt;h2 id="prerequisites">
 Prerequisites
 &lt;a class="anchor" href="#prerequisites">#&lt;/a>
&lt;/h2>
&lt;p>&lt;strong>Good news!&lt;/strong> uv doesn&amp;rsquo;t require Python to be pre-installed - it can manage Python installations for you. However, having Python already installed won&amp;rsquo;t hurt.&lt;/p>
&lt;h2 id="installing-uv">
 Installing uv
 &lt;a class="anchor" href="#installing-uv">#&lt;/a>
&lt;/h2>
&lt;h3 id="-linux---macos">
 ðŸ§ Linux &amp;amp; ðŸŽ macOS
 &lt;a class="anchor" href="#-linux---macos">#&lt;/a>
&lt;/h3>
&lt;p>The fastest way to install uv is using the official installer:&lt;/p></description></item><item><title>Backtracking memo</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/backtracking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/backtracking/</guid><description>&lt;h1 id="backtracking-procedure-for-step-size-selection">
 Backtracking procedure for step size selection
 &lt;a class="anchor" href="#backtracking-procedure-for-step-size-selection">#&lt;/a>
&lt;/h1>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;p>The backtracking line search is a fundamental technique in optimization algorithms for determining an appropriate step size that ensures sufficient decrease in the objective function. This procedure is particularly useful in gradient-based methods where choosing an optimal step size analytically is difficult or computationally expensive.&lt;/p>
&lt;h2 id="mathematical-setup">
 Mathematical setup
 &lt;a class="anchor" href="#mathematical-setup">#&lt;/a>
&lt;/h2>
&lt;p>Consider the optimization problem:
$\min_{\mathbf{x} \in \mathbb{R}^n} f(\mathbf{x})$&lt;/p>
&lt;p>where $f: \mathbb{R}^n \to \mathbb{R}$ is a continuously differentiable function. At iteration $k$, we have:&lt;/p></description></item><item><title>Quasi-Newton methods memo</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/quasinewton/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/quasinewton/</guid><description>&lt;h1 id="bfgs-and-sr1-quasi-newton-methods">
 BFGS and SR1 Quasi-Newton Methods
 &lt;a class="anchor" href="#bfgs-and-sr1-quasi-newton-methods">#&lt;/a>
&lt;/h1>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;p>Quasi-Newton methods are a class of optimization algorithms that approximate the Newton direction without requiring explicit computation of the Hessian matrix. These methods achieve superlinear convergence while avoiding the computational expense and potential numerical difficulties associated with second derivatives. The two most prominent quasi-Newton methods are the BFGS (Broyden-Fletcher-Goldfarb-Shanno) and SR1 (Symmetric Rank-One) methods.&lt;/p>
&lt;h2 id="mathematical-setup">
 Mathematical setup
 &lt;a class="anchor" href="#mathematical-setup">#&lt;/a>
&lt;/h2>
&lt;p>Consider the optimization problem:
$\min_{\mathbf{x} \in \mathbb{R}^n} f(\mathbf{x})$&lt;/p></description></item></channel></rss>