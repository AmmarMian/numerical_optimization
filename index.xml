<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on Numerical optimization</title><link>http://ammarmian.github.io/numerical_optimization/</link><description>Recent content in Introduction on Numerical optimization</description><generator>Hugo</generator><language>fr</language><atom:link href="http://ammarmian.github.io/numerical_optimization/index.xml" rel="self" type="application/rss+xml"/><item><title>1. From Linear regression to perceptron</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/perceptron/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/perceptron/</guid><description>&lt;h1 id="from-linear-regression-to-perceptron">
 From Linear regression to perceptron
 &lt;a class="anchor" href="#from-linear-regression-to-perceptron">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>1. Optimization problems</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/optimization_problems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/optimization_problems/</guid><description>&lt;h1 id="optimization-problems">
 Optimization problems
 &lt;a class="anchor" href="#optimization-problems">#&lt;/a>
&lt;/h1>
&lt;h2 id="unconstrained-vs-constrained">
 Unconstrained vs constrained
 &lt;a class="anchor" href="#unconstrained-vs-constrained">#&lt;/a>
&lt;/h2>
&lt;p>What we are interested in these lectures is to solve problems of the form :&lt;/p>
&lt;p>\begin{equation}
\underset{\mathbf{x}\in\mathbb{R}^d}{\operatorname{(arg)min}} f(\mathbf{x}),
\label{eq: optim general unconstrained}
\end{equation}
where $\mathbf{x}\in\mathbb{R}^d$ and $f:\mathcal{D}_f \mapsto \mathbb{R} $ is a scalar-valued function with domain $\mathcal{D}_f$. Under this formulation, the problem is said to be an &lt;strong>unconstrained optimization&lt;/strong> problem.&lt;/p>
&lt;p>If additionally, we add a set of equalities constraints functions:
$$
\{h_i : \mathbb{R}^d \mapsto \mathbb{R} \, /\, 1 \leq i \leq N \}
$$
and inequalities constraints functions:
$$
\{g_j : \mathbb{R}^d \mapsto \mathbb{R} \, /\, 1 \leq j \leq M \}
$$
and define the set $\mathcal{S} = \{\mathbf{x} \in \mathbb{R}^d \,/\, \forall\,(i, j),\, h_i(\mathbf{x})=0,\, g_j(\mathbf{x})\leq 0\}$ and want to solve:
\begin{equation}
\underset{\mathbf{x}\in\mathcal{S}}{\operatorname{(arg)min}} f(\mathbf{x}),
\label{eq: optim general constrained}
\end{equation}
then the problem is said to be a &lt;strong>constrained optimization&lt;/strong> problem.&lt;/p></description></item><item><title>1. Unconstrained optimization : Second-order</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/unconstrained_newton/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/unconstrained_newton/</guid><description>&lt;h1 id="unconstrained-optimization----second-order-methods">
 Unconstrained optimization - Second-order methods
 &lt;a class="anchor" href="#unconstrained-optimization----second-order-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>We have seen in the previous chapter that first-order methods, such as steepest descent, are often used to find a local minimum of a function $f(\mathbf{x})$. However, these methods can be slow to converge, especially when the function has ill-conditioned Hessian or when the initial guess is far from the solution. Second-order methods, which use information about the curvature of the function, can provide faster convergence rates.&lt;/p></description></item><item><title>Linear Algebra</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/linear_algebra/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/linear_algebra/</guid><description>&lt;h1 id="fundamentals-of-linear-algebra">
 Fundamentals of Linear Algebra
 &lt;a class="anchor" href="#fundamentals-of-linear-algebra">#&lt;/a>
&lt;/h1>
&lt;h2 id="1---introduction">
 1 - Introduction
 &lt;a class="anchor" href="#1---introduction">#&lt;/a>
&lt;/h2>
&lt;blockquote>
&lt;p>Linear algebra is one of the foundational branches of mathematics, with applications spanning from engineering and computer science to economics and physics. This document is extracted from the textbook &lt;strong>Matrix Differential Calculus with Applications in Statistics and Econometrics&lt;/strong> from Jan R. Magnus; Heinz Neudecker, adapting the notations to the ones used in the lectures.&lt;/p>
&lt;/blockquote>
&lt;p>In this chapter, we summarize some of the well-known definitions and theorems of matrix algebra. Most of the theorems will be proved.&lt;/p></description></item><item><title>2. Proximal methods</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/proximal_methods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/proximal_methods/</guid><description>&lt;h1 id="proximal-methods">
 Proximal methods
 &lt;a class="anchor" href="#proximal-methods">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>2. Support Vector Machine</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/svm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/svm/</guid><description>&lt;h1 id="support-vector-machine">
 Support Vector Machine
 &lt;a class="anchor" href="#support-vector-machine">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>2. Unconstrained optimization : basics</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/</guid><description>&lt;h1 id="unconstrained-optimization---basics">
 Unconstrained optimization - basics
 &lt;a class="anchor" href="#unconstrained-optimization---basics">#&lt;/a>
&lt;/h1>
&lt;p>We hereby consider problems without any constraints on the set of admissible solutions, i.e we aim to solve:
$$
\underset{\mathbf{x}\in\mathbb{R}^d}{\operatorname{argmin}} f(\mathbf{x}).
$$&lt;/p>
&lt;p>Let us try to characterizes the nature of the solutions under this setup.&lt;/p>
&lt;h2 id="what-is-a-solution-">
 What is a solution ?
 &lt;a class="anchor" href="#what-is-a-solution-">#&lt;/a>
&lt;/h2>








&lt;figure id="figure-%!s(int=2)-1">&lt;img src="%20../../../../../../tikZ/local_global_minima/main.svg"
 alt="Local vs global" width="600px">
 &lt;figcaption>
 &lt;p>
 &lt;strong>Figure 2.1: &lt;/strong>Local and global minimum can coexist.&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>Generally, we would be happiest if we found a global minimizer of $f$ , a point where the
function attains its least value. A formal definition is :&lt;/p></description></item><item><title>Differentiation</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/differentiation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/differentiation/</guid><description>&lt;h1 id="differentiation-in-multiple-dimensions">
 Differentiation in Multiple Dimensions
 &lt;a class="anchor" href="#differentiation-in-multiple-dimensions">#&lt;/a>
&lt;/h1>
&lt;h2 id="1---introduction">
 1 - Introduction
 &lt;a class="anchor" href="#1---introduction">#&lt;/a>
&lt;/h2>
&lt;blockquote>
&lt;p>Differentiation provides the mathematical framework for understanding how functions change locally. While single-variable calculus introduces derivatives, most applications require working with functions of multiple variables. This chapter extends differentiation concepts to multivariate and matrix-valued functions, building the tools needed for optimization and analysis in higher dimensions.&lt;/p>
&lt;/blockquote>
&lt;h2 id="2---monovariate-reminders">
 2 - Monovariate Reminders
 &lt;a class="anchor" href="#2---monovariate-reminders">#&lt;/a>
&lt;/h2>
&lt;h3 id="derivative-of-a-function">
 Derivative of a Function
 &lt;a class="anchor" href="#derivative-of-a-function">#&lt;/a>
&lt;/h3>










&lt;div id="derivative_definition" class="theorem-box">
 &lt;p class="theorem-title">&lt;strong>Definition 0.1 (Derivative)&lt;/strong>&lt;/p></description></item><item><title>Introduction</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/1_introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/1_introduction/</guid><description>&lt;h1 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h1>
&lt;h2 id="notations">
 Notations
 &lt;a class="anchor" href="#notations">#&lt;/a>
&lt;/h2>
&lt;p>Let us start by defining the notation used troughout all the lectures and practical labs.&lt;/p>
&lt;h3 id="basic-notation">
 Basic Notation
 &lt;a class="anchor" href="#basic-notation">#&lt;/a>
&lt;/h3>
&lt;p>Scalars are represented by italic letters (e.g., $x$, $y$, $\lambda$). Vectors are denoted by bold lowercase letters (e.g., $\mathbf{v}$, $\mathbf{x}$), while matrices are represented by bold uppercase letters (e.g., $\mathbf{A}$, $\mathbf{B}$). The dimensionality of a vector $\mathbf{v} \in \mathbb{R}^n$ indicates it contains $n$ elements, and similarly, a matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$ has $m$ rows and $n$ columns.&lt;/p></description></item><item><title>3. Convexity theory</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/convexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/convexity/</guid><description>&lt;h1 id="convexity-theory">
 Convexity theory
 &lt;a class="anchor" href="#convexity-theory">#&lt;/a>
&lt;/h1>
&lt;p>Convexity is a powerful property of functions and sets that simplifies the analysis of optimization problems and the characterization of global minimizers. In this chapter, we will explore the concepts of convex sets, convex functions, and their implications for unconstrained optimization.&lt;/p>
&lt;h2 id="convex-sets">
 Convex sets
 &lt;a class="anchor" href="#convex-sets">#&lt;/a>
&lt;/h2>
&lt;p>Let us first start by defining the convexity of a given set $\mathcal{S}\subset\mathbb{R}^d$:&lt;/p>










&lt;div id="convex_set" class="theorem-box">
 &lt;p class="theorem-title">&lt;strong>Definition 3.1 (Convex set)&lt;/strong>&lt;/p>
 &lt;div class="theorem-content">
 Let $\mathcal{S}\subset\mathbb{R}^d$ be a set. The set $\mathcal{S}$ is convex if, for any two points $\mathbf{x}, \mathbf{y} \in \mathcal{S}$, the line segment that connects them is also contained in $\mathcal{S}$, that is,
\begin{equation}
\mathbf{x}, \mathbf{y} \in \mathcal{S} \implies \lambda \mathbf{x} + (1-\lambda) \mathbf{y} \in \mathcal{S}, \quad \forall \lambda \in [0, 1].
\label{eq:convex_set}
\end{equation}
 &lt;/div>
&lt;/div>


&lt;div class="center-container">
 &lt;div class="center-content">
 








&lt;figure id="convex_set">&lt;img src="%20../../../../../../tikZ/convex_set/main.svg"
 alt="Zig zag" width="400px">
 &lt;figcaption>
 &lt;p>
 &lt;strong>Figure 3.1: &lt;/strong>Convex set&lt;/p></description></item><item><title>3. Neural Networks</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/neural_networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/neural_networks/</guid><description>&lt;h1 id="neural-networks">
 Neural Networks
 &lt;a class="anchor" href="#neural-networks">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>4. Modern trends</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/modern/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/modern/</guid><description>&lt;h1 id="modern-trends">
 Modern trends
 &lt;a class="anchor" href="#modern-trends">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>4. Unconstrained optimization : linesearch</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/</guid><description>&lt;h1 id="unconstrained-optimization---linesearch-methods">
 Unconstrained optimization - Linesearch methods
 &lt;a class="anchor" href="#unconstrained-optimization---linesearch-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>All algorithms for unconstrained minimization require the user to supply a starting point, which we usually denote by $\mathbf{x}_0$. The user with knowledge about the application and the data set may be in a good position to choose $\mathbf{x}_0$ to be a reasonable estimate of the solution. Otherwise, the starting point must be chosen in some arbitrary manner.&lt;/p></description></item><item><title>5. Constrained optimization - Introduction</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/</guid><description>&lt;h1 id="constrained-optimization-methods">
 Constrained optimization methods
 &lt;a class="anchor" href="#constrained-optimization-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>The second part of this lecture is about minimizing functions subject to constraints on the variables. A general formulation for these problems is&lt;/p>
&lt;p>$$
\min_{\mathbf{x} \in \mathrm{R}^{n}} f(\mathbf{x}) \quad \text { subject to } \quad \begin{cases}c_{i}(\mathbf{x})=0, &amp;amp; i \in \mathcal{E}, \\ c_{i}(\mathbf{x}) \geq 0, &amp;amp; i \in \mathcal{I},\end{cases}
$$&lt;/p></description></item><item><title>I - Linear Regression models</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/linear_regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/linear_regression/</guid><description>&lt;h1 id="linear-regression-models">
 Linear Regression models
 &lt;a class="anchor" href="#linear-regression-models">#&lt;/a>
&lt;/h1>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;p>In this lab session, we will explore the fundamental concepts of numerical optimization through the lens of linear regression. We&amp;rsquo;ll begin with the simplest case and gradually build up to more complex scenarios, comparing analytical solutions with numerical methods at each step.&lt;/p>
&lt;p>Linear regression is perhaps the most fundamental problem in machine learning and statistics. While it has a closed-form solution, implementing numerical optimization methods for this problem provides excellent intuition for more complex optimization scenarios where analytical solutions don&amp;rsquo;t exist.&lt;/p></description></item><item><title>II - Remote Sensing Project</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/remote_sensing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/remote_sensing/</guid><description>&lt;h1 id="solving-inverse-problems-in-remote-sensing">
 Solving Inverse Problems in Remote Sensing
 &lt;a class="anchor" href="#solving-inverse-problems-in-remote-sensing">#&lt;/a>
&lt;/h1>
&lt;h2 id="readme">
 README
 &lt;a class="anchor" href="#readme">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>To get all the material for the labs, clone the following git repo : &lt;a href="https://github.com/y-mhiri/hsi_unmixing_lab">https://github.com/y-mhiri/hsi_unmixing_lab&lt;/a>.&lt;/li>
&lt;li>You can follow this lab in multiple level of difficulty&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>&lt;strong>The easiest way&lt;/strong> : Answer only the theoretical question and follow the notebooks in &lt;code>notebooks/&lt;/code> to do the programming&lt;/li>
&lt;li>&lt;strong>Intermediary level&lt;/strong> : Implement your own code to answer the lab questions using the helper functions you&amp;rsquo;ll find in &lt;code>src/&lt;/code>&lt;/li>
&lt;li>&lt;strong>Expert level&lt;/strong> : I guess you don&amp;rsquo;t even need to clone the git repo&amp;hellip;&lt;/li>
&lt;/ol>
&lt;p>If anything don&amp;rsquo;t hesitate to reach me at &lt;code>yassine.mhiri@univ-smb.fr&lt;/code>.&lt;/p></description></item><item><title>III - Digit recognition</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/mnist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/mnist/</guid><description>&lt;h1 id="digit-recognition-with-multi-layer-perceptron">
 Digit recognition with multi-layer perceptron
 &lt;a class="anchor" href="#digit-recognition-with-multi-layer-perceptron">#&lt;/a>
&lt;/h1>
&lt;p>Soon to be added.&lt;/p></description></item><item><title>Lab environment</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/environment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/environment/</guid><description>&lt;h1 id="lab-environment-setup">
 Lab Environment Setup
 &lt;a class="anchor" href="#lab-environment-setup">#&lt;/a>
&lt;/h1>
&lt;p>Welcome to the numerical optimization course! This page will guide you through setting up a modern, efficient Python environment using &lt;strong>uv&lt;/strong>.&lt;/p>
&lt;h2 id="prerequisites">
 Prerequisites
 &lt;a class="anchor" href="#prerequisites">#&lt;/a>
&lt;/h2>
&lt;p>&lt;strong>Good news!&lt;/strong> uv doesn&amp;rsquo;t require Python to be pre-installed - it can manage Python installations for you. However, having Python already installed won&amp;rsquo;t hurt.&lt;/p>
&lt;h2 id="installing-uv">
 Installing uv
 &lt;a class="anchor" href="#installing-uv">#&lt;/a>
&lt;/h2>
&lt;h3 id="-linux---macos">
 ðŸ§ Linux &amp;amp; ðŸŽ macOS
 &lt;a class="anchor" href="#-linux---macos">#&lt;/a>
&lt;/h3>
&lt;p>The fastest way to install uv is using the official installer:&lt;/p></description></item><item><title>Backtracking memo</title><link>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/backtracking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/practical_labs/backtracking/</guid><description>&lt;h1 id="backtracking-procedure-for-step-size-selection">
 Backtracking procedure for step size selection
 &lt;a class="anchor" href="#backtracking-procedure-for-step-size-selection">#&lt;/a>
&lt;/h1>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;p>The backtracking line search is a fundamental technique in optimization algorithms for determining an appropriate step size that ensures sufficient decrease in the objective function. This procedure is particularly useful in gradient-based methods where choosing an optimal step size analytically is difficult or computationally expensive.&lt;/p>
&lt;h2 id="mathematical-setup">
 Mathematical setup
 &lt;a class="anchor" href="#mathematical-setup">#&lt;/a>
&lt;/h2>
&lt;p>Consider the optimization problem:
$\min_{\mathbf{x} \in \mathbb{R}^n} f(\mathbf{x})$&lt;/p>
&lt;p>where $f: \mathbb{R}^n \to \mathbb{R}$ is a continuously differentiable function. At iteration $k$, we have:&lt;/p></description></item></channel></rss>