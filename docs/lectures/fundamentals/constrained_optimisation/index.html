<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Constrained optimization methods
  #

The second part of this lecture is about minimizing functions subject to constraints on the variables. A general formulation for these problems is
$$
\min_{\mathbf{x} \in \mathrm{R}^{n}} f(\mathbf{x}) \quad \text { subject to } \quad \begin{cases}c_{i}(\mathbf{x})=0, & i \in \mathcal{E}, \\ c_{i}(\mathbf{x}) \geq 0, & i \in \mathcal{I},\end{cases}
$$
where $f$ and the functions $c_{i}$ are all smooth, real-valued functions on a subset of $\mathbb{R}^{n}$, and $\mathcal{I}$ and $\mathcal{E}$ are two finite sets of indices. As before, we call $f$ the objective function, while $c_{i}$, $i \in \mathcal{E}$ are the equality constraints and $c_{i}, i \in \mathcal{I}$ are the inequality constraints. We define the feasible set $\Omega$ to be the set of points $\mathbf{x}$ that satisfy the constraints; that is,"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/"><meta property="og:site_name" content="Numerical optimization"><meta property="og:title" content="6. Constrained optimization - introduction"><meta property="og:description" content="Constrained optimization methods # The second part of this lecture is about minimizing functions subject to constraints on the variables. A general formulation for these problems is
$$ \min_{\mathbf{x} \in \mathrm{R}^{n}} f(\mathbf{x}) \quad \text { subject to } \quad \begin{cases}c_{i}(\mathbf{x})=0, & i \in \mathcal{E}, \\ c_{i}(\mathbf{x}) \geq 0, & i \in \mathcal{I},\end{cases} $$
where $f$ and the functions $c_{i}$ are all smooth, real-valued functions on a subset of $\mathbb{R}^{n}$, and $\mathcal{I}$ and $\mathcal{E}$ are two finite sets of indices. As before, we call $f$ the objective function, while $c_{i}$, $i \in \mathcal{E}$ are the equality constraints and $c_{i}, i \in \mathcal{I}$ are the inequality constraints. We define the feasible set $\Omega$ to be the set of points $\mathbf{x}$ that satisfy the constraints; that is,"><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>6. Constrained optimization - introduction | Numerical optimization</title>
<link rel=icon href=/numerical_optimization/favicon.png><link rel=manifest href=/numerical_optimization/manifest.json><link rel=canonical href=http://ammarmian.github.io/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/><link rel=stylesheet href=/numerical_optimization/book.min.a8206ca0e1caaf803f4ef219929830ceb3f1ae72968a1975640344969b7a9c50.css integrity="sha256-qCBsoOHKr4A/TvIZkpgwzrPxrnKWihl1ZANElpt6nFA=" crossorigin=anonymous><script defer src=/numerical_optimization/fuse.min.js></script><script defer src=/numerical_optimization/en.search.min.ef8cd72fdbc7f6f64e6a9a1e64ce8eaa194d55a900e2a33b56d3daed9f52ab7e.js integrity="sha256-74zXL9vH9vZOapoeZM6OqhlNVakA4qM7VtPa7Z9Sq34=" crossorigin=anonymous></script><script>const chapterNum=6;MathJax={section:chapterNum,loader:{load:["[tex]/tagformat"]},tex:{packages:{"[+]":["tagformat"]},inlineMath:[["\\\\(","\\\\)"],["$","$"]],displayMath:[["\\[","\\]"],["$$","$$"]],processEnvironments:!0,processRefs:!0,tags:"ams",tagformat:{number:e=>MathJax.config.section+"."+e,id:e=>"eqn-id:"+e}},startup:{ready(){MathJax.startup.defaultReady(),MathJax.startup.input[0].preFilters.add(({math:e})=>{e.inputData.recompile&&(MathJax.config.section=e.inputData.recompile.section)}),MathJax.startup.input[0].postFilters.add(({math:e})=>{e.inputData.recompile&&(e.inputData.recompile.section=MathJax.config.section)})}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js defer></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/numerical_optimization/><span>Numerical optimization</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><a href=/numerical_optimization/docs/lectures/>Lectures</a><ul><li><a href=/numerical_optimization/docs/lectures/1_introduction/>Introduction</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/>I - Fundamentals</a><ul><li><a href=/numerical_optimization/docs/lectures/fundamentals/optimization_problems/>1. Optimization problems</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/>2. Unconstrained optimization : basics</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/convexity/>3. Convexity theory</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/>4. Unconstrained optimization : linesearch</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/ class=active>6. Constrained optimization - introduction</a></li></ul></li><li><a href=/numerical_optimization/docs/lectures/advanced/>II - Advanced problems</a><ul><li><a href=/numerical_optimization/docs/lectures/advanced/unconstrained_newton/>1. Unconstrained optimization : Second-order</a></li><li><a href=/numerical_optimization/docs/lectures/advanced/proximal_methods/>2. Proximal methods</a></li></ul></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/>III - Machine Learning problems</a><ul><li><a href=/numerical_optimization/docs/lectures/machine_learning/perceptron/>1. From Linear regression to perceptron</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/svm/>2. Support Vector Machine</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/neural_networks/>3. Neural Networks</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/modern/>4. Modern trends</a></li></ul></li><li><input type=checkbox id=section-28bd40dd904095dea2d407e437b9446e class=toggle>
<label for=section-28bd40dd904095dea2d407e437b9446e class="flex justify-between"><a href=/numerical_optimization/docs/lectures/reminders/>Reminders</a></label><ul><li><a href=/numerical_optimization/docs/lectures/reminders/differentiation/>Differentiation</a></li><li><a href=/numerical_optimization/docs/lectures/reminders/linear_algebra/>Linear Algebra</a></li></ul></li></ul></li><li class=book-section-flat><a href=/numerical_optimization/docs/practical_labs/>Practical labs</a><ul><li><a href=/numerical_optimization/docs/practical_labs/linear_regression/>I - Linear Regression models</a></li><li><a href=/numerical_optimization/docs/practical_labs/remote_sensing/>II - Remote Sensing project</a></li><li><a href=/numerical_optimization/docs/practical_labs/mnist/>III - Digit recognition</a></li><li><a href=/numerical_optimization/docs/practical_labs/environment/>Lab environment</a></li><li><a href=/numerical_optimization/docs/practical_labs/backtracking/>Backtracking memo</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/numerical_optimization/svg/menu.svg class=book-icon alt=Menu></label><h3>6. Constrained optimization - introduction</h3><label for=toc-control><img src=/numerical_optimization/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#local-and-global-solutions>Local and global solutions</a></li><li><a href=#smoothness>Smoothness</a><ul><li><a href=#examples>Examples</a></li></ul></li><li><a href=#two-inequality-constraints>Two inequality constraints</a><ul><li><a href=#first-order-optimality-conditions>First-order optimality conditions</a></li></ul></li><li><a href=#statement-of-first-order-necessary-conditions>Statement of first-order necessary conditions</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=constrained-optimization-methods>Constrained optimization methods
<a class=anchor href=#constrained-optimization-methods>#</a></h1><p>The second part of this lecture is about minimizing functions subject to constraints on the variables. A general formulation for these problems is</p><p>$$
\min_{\mathbf{x} \in \mathrm{R}^{n}} f(\mathbf{x}) \quad \text { subject to } \quad \begin{cases}c_{i}(\mathbf{x})=0, & i \in \mathcal{E}, \\ c_{i}(\mathbf{x}) \geq 0, & i \in \mathcal{I},\end{cases}
$$</p><p>where $f$ and the functions $c_{i}$ are all smooth, real-valued functions on a subset of $\mathbb{R}^{n}$, and $\mathcal{I}$ and $\mathcal{E}$ are two finite sets of indices. As before, we call $f$ the objective function, while $c_{i}$, $i \in \mathcal{E}$ are the equality constraints and $c_{i}, i \in \mathcal{I}$ are the inequality constraints. We define the feasible set $\Omega$ to be the set of points $\mathbf{x}$ that satisfy the constraints; that is,</p><p>$$
\Omega=\left\{\mathbf{x} \mid c_{i}(\mathbf{x})=0, \quad i \in \mathcal{E} ; \quad c_{i}(\mathbf{x}) \geq 0, \quad i \in \mathcal{I}\right\}
$$</p><p>so that we can rewrite the problem more compactly as</p><p>\begin{equation}
\min_{\mathbf{x} \in \Omega} f(\mathbf{x}).
\label{eq:constrained_problem}
\end{equation}</p><p>In this chapter we derive mathematical characterizations of the solutions of \eqref{eq:constrained_problem}. Recall that for the unconstrained optimization problem, we characterized solution points $\mathbf{x}^{\star}$ in the following way:</p><p>Necessary conditions: Local minima of unconstrained problems have $\nabla f\left(\mathbf{x}^{\star}\right)=0$ and $\nabla^{2} f\left(\mathbf{x}^{\star}\right)$ positive semidefinite.</p><p>Sufficient conditions: Any point $\mathbf{x}^{\star}$ at which $\nabla f\left(\mathbf{x}^{\star}\right)=0$ and $\nabla^{2} f\left(\mathbf{x}^{\star}\right)$ is positive definite is a strong local minimizer of $f$.</p><p>Our aim in this chapter is to derive similar conditions to characterize the solutions of constrained optimization problems.</p><h2 id=local-and-global-solutions>Local and global solutions
<a class=anchor href=#local-and-global-solutions>#</a></h2><p>We have seen already that global solutions are difficult to find even when there are no constraints. The situation may be improved when we add constraints, since the feasible set might exclude many of the local minima and it may be comparatively easy to pick the global minimum from those that remain. However, constraints can also make things much more difficult. As an example, consider the problem</p><p>$$
\min_{\mathbf{x} \in \mathrm{R}^{n}}\|\mathbf{x}\|_{2}^{2}, \quad \text { subject to }\|\mathbf{x}\|_{2}^{2} \geq 1
$$</p><p>Without the constraint, this is a convex quadratic problem with unique minimizer $\mathbf{x}=\mathbf{0}$. When the constraint is added, any vector $\mathbf{x}$ with $\|\mathbf{x}\|_{2}=1$ solves the problem. There are infinitely many such vectors (hence, infinitely many local minima) whenever $n \geq 2$.</p><p>A second example shows how addition of a constraint produces a large number of local solutions that do not form a connected set. Consider</p><p>$$
\min \left(x_{2}+100\right)^{2}+0.01 x_{1}^{2}, \quad \text { subject to } x_{2}-\cos x_{1} \geq 0
$$</p><p>Without the constraint, the problem has the unique solution $(-100,0)$. With the constraint there are local solutions near the points</p><p>$$
\left(x_{1}, x_{2}\right)=(k \pi,-1), \quad \text { for } \quad k= \pm 1, \pm 3, \pm 5, \ldots
$$</p><div id=local_solution class=theorem-box><p class=theorem-title><strong>Definition 6.1 (Local solution)</strong></p><div class=theorem-content>A vector $\mathbf{x}^{\star}$ is a <strong>local solution</strong> of the problem \eqref{eq:constrained_problem} if $\mathbf{x}^{\star} \in \Omega$ and there is a neighborhood $\mathcal{N}$ of $\mathbf{x}^{\star}$ such that $f(\mathbf{x}) \geq f\left(\mathbf{x}^{\star}\right)$ for $\mathbf{x} \in \mathcal{N} \cap \Omega$.</div></div><p>Similarly, we can make the following definitions:</p><div id=strict_local_solution class=theorem-box><p class=theorem-title><strong>Definition 6.2 (Strict local solution)</strong></p><div class=theorem-content>A vector $\mathbf{x}^{\star}$ is a <strong>strict local solution</strong> (also called a strong local solution) if $\mathbf{x}^{\star} \in \Omega$ and there is a neighborhood $\mathcal{N}$ of $\mathbf{x}^{\star}$ such that $f(\mathbf{x})>f\left(\mathbf{x}^{\star}\right)$ for all $\mathbf{x} \in \mathcal{N} \cap \Omega$ with $\mathbf{x} \neq \mathbf{x}^{\star}$.</div></div><div id=isolated_local_solution class=theorem-box><p class=theorem-title><strong>Definition 6.3 (Isolated local solution)</strong></p><div class=theorem-content>A point $\mathbf{x}^{\star}$ is an <strong>isolated local solution</strong> if $\mathbf{x}^{\star} \in \Omega$ and there is a neighborhood $\mathcal{N}$ of $\mathbf{x}^{\star}$ such that $\mathbf{x}^{\star}$ is the only local minimizer in $\mathcal{N} \cap \Omega$.</div></div><p>At times, we replace the word &ldquo;solution&rdquo; by &ldquo;minimizer&rdquo; in our discussion. This alternative is frequently used in the literature, but it is slightly less satisfying because it does not account for the role of the constraints in defining the point in question.</p><h2 id=smoothness>Smoothness
<a class=anchor href=#smoothness>#</a></h2><p>Smoothness of objective functions and constraints is an important issue in characterizing solutions, just as in the unconstrained case. It ensures that the objective function and the constraints all behave in a reasonably predictable way and therefore allows algorithms to make good choices for search directions.</p><p>We saw earlier that graphs of nonsmooth functions contain &ldquo;kinks&rdquo; or &ldquo;jumps&rdquo; where the smoothness breaks down. If we plot the feasible region for any given constrained optimization problem, we usually observe many kinks and sharp edges. Does this mean that the constraint functions that describe these regions are nonsmooth? The answer is often no, because the nonsmooth boundaries can often be described by a collection of smooth constraint functions. A diamond-shaped feasible region in $\mathbb{R}^{2}$ could be described by the single nonsmooth constraint</p><p>$$
\|\mathbf{x}\|_{1}=\left|x_{1}\right|+\left|x_{2}\right| \leq 1 .
$$</p><div class=center-container><div class=center-content><figure id="figure-%!s(int=6)-1"><img src=%20../../../../../../tikZ/nonsmooth_tosmooth_constraints/main.svg alt="nonsmooth constraints can be described by smooth constraints" width=300px><figcaption><p><strong>Figure 6.1: </strong>Nonsmooth constraints can be described by smooth constraints</p></figcaption></figure></div></div><p>It can also be described by the following set of smooth (in fact, linear) constraints:</p><p>$$
x_{1}+x_{2} \leq 1, \quad x_{1}-x_{2} \leq 1, \quad -x_{1}+x_{2} \leq 1, \quad -x_{1}-x_{2} \leq 1
$$</p><p>Each of the four constraints represents one edge of the feasible polytope. In general, the constraint functions are chosen so that each one represents a smooth piece of the boundary of $\Omega$.</p><p>Nonsmooth, unconstrained optimization problems can sometimes be reformulated as smooth constrained problems. An example is given by the unconstrained scalar problem of minimizing a nonsmooth function $f(x)$ defined by</p><p>$$
f(x)=\max \left(x^{2}, x\right),
$$</p><p>which has kinks at $x=0$ and $x=1$, and the solution at $x^{\star}=0$. We obtain a smooth, constrained formulation of this problem by adding an artificial variable $t$ and writing</p><p>$$
\min t \quad \text { s.t. } \quad t \geq x, \quad t \geq x^{2} .
$$</p><p>Reformulation techniques such as these are used often in cases where $f$ is a maximum of a collection of functions or when $f$ is a 1 -norm or $\infty$-norm of a vector function.</p><p>In the examples above we expressed inequality constraints in a slightly different way from the form $c_{i}(\mathbf{x}) \geq 0$ that appears in the definition. However, any collection of inequality constraints with $\geq$ and $\leq$ and nonzero right-hand-sides can be expressed in the form $c_{i}(\mathbf{x}) \geq 0$ by simple rearrangement of the inequality. In general, it is good practice to state the constraint in a way that is intuitive and easy to understand.</p><h3 id=examples>Examples
<a class=anchor href=#examples>#</a></h3><p>To introduce the basic principles behind the characterization of solutions of constrained optimization problems, we work through three simple examples. The ideas discussed here will be made rigorous in the sections that follow.</p><p>We start by noting one item of terminology that recurs throughout the rest of the lecture: At a feasible point $\mathbf{x}$, the inequality constraint $i \in \mathcal{I}$ is said to be active if $c_{i}(\mathbf{x})=0$ and inactive if the strict inequality $c_{i}(\mathbf{x})>0$ is satisfied.</p><h4 id=a-single-equality-constraint>A single equality constraint
<a class=anchor href=#a-single-equality-constraint>#</a></h4><p><strong>Example 1</strong></p><p>Our first example is a two-variable problem with a single equality constraint:</p><p>\begin{equation}
\min x_{1}+x_{2} \quad \text { s.t. } \quad x_{1}^{2}+x_{2}^{2}-2=0.
\label{eq:equality_example}
\end{equation}</p><div class=center-container><div class=center-content><figure id="figure-%!s(int=6)-2"><img src=%20../../../../../../tikZ/single_equality_cosntraint/main.svg alt="constraints and gradient of function" width=300px><figcaption><p><strong>Figure 6.2: </strong>Constraints and gradient of function</p></figcaption></figure></div></div><p>In the general form, we have $f(\mathbf{x})=x_{1}+x_{2}, \mathcal{I}=\emptyset, \mathcal{E}=\{1\}$, and $c_{1}(\mathbf{x})=x_{1}^{2}+x_{2}^{2}-2$. We can see by inspection that the feasible set for this problem is the circle of radius $\sqrt{2}$ centered at the origin-just the boundary of this circle, not its interior. The solution $\mathbf{x}^{\star}$ is obviously $(-1,-1)^{\mathrm{T}}$. From any other point on the circle, it is easy to find a way to move that stays feasible (that is, remains on the circle) while decreasing $f$. For instance, from the point $\mathbf{x}=(\sqrt{2}, 0)^{\mathrm{T}}$ any move in the clockwise direction around the circle has the desired effect.</p><p>We also see that at the solution $\mathbf{x}^{\star}$, the constraint normal $\nabla c_{1}\left(\mathbf{x}^{\star}\right)$ is parallel to $\nabla f\left(\mathbf{x}^{\star}\right)$. That is, there is a scalar $\lambda_{1}^{\star}$ such that</p><p>\begin{equation}
\nabla f\left(\mathbf{x}^{\star}\right)=\lambda_{1}^{\star} \nabla c_{1}\left(\mathbf{x}^{\star}\right).
\label{eq:parallel_gradients}
\end{equation}</p><p>(In this particular case, we have $\lambda_{1}^{\star}=-\frac{1}{2}$.)</p><p>We can derive \eqref{eq:parallel_gradients} by examining first-order Taylor series approximations to the objective and constraint functions. To retain feasibility with respect to the function $c_{1}(\mathbf{x})=0$, we require that $c_{1}(\mathbf{x}+\mathbf{d})=0$; that is,</p><p>$$
0=c_{1}(\mathbf{x}+\mathbf{d}) \approx c_{1}(\mathbf{x})+\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d}=\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d}
$$</p><p>Hence, the direction $\mathbf{d}$ retains feasibility with respect to $c_{1}$, to first order, when it satisfies</p><p>$$
\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d}=0
$$</p><p>Similarly, a direction of improvement must produce a decrease in $f$, so that</p><p>$$
0>f(\mathbf{x}+\mathbf{d})-f(\mathbf{x}) \approx \nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}
$$</p><p>or, to first order,</p><p>$$
\nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}&lt;0
$$</p><p>If there exists a direction $\mathbf{d}$ that satisfies both conditions, we conclude that improvement on our current point $\mathbf{x}$ is possible. It follows that a necessary condition for optimality for the problem \eqref{eq:equality_example} is that there exist no direction $\mathbf{d}$ satisfying both conditions.</p><p>By drawing a picture (see visualization below), the reader can check that the only way that such a direction cannot exist is if $\nabla f(\mathbf{x})$ and $\nabla c_{1}(\mathbf{x})$ are parallel, that is, if the condition $\nabla f(\mathbf{x})=\lambda_{1} \nabla c_{1}(\mathbf{x})$ holds at $\mathbf{x}$, for some scalar $\lambda_{1}$. If this condition is not satisfied, the direction defined by</p><p>$$
\mathbf{d}=-\left(\mathbf{I}-\frac{\nabla c_{1}(\mathbf{x}) \nabla c_{1}(\mathbf{x})^{\mathrm{T}}}{\|\nabla c_{1}(\mathbf{x})\|^{2}}\right) \nabla f(\mathbf{x})
$$</p><p>satisfies both conditions.</p><p>By introducing the Lagrangian function</p><p>$$
\mathcal{L}\left(\mathbf{x}, \lambda_{1}\right)=f(\mathbf{x})-\lambda_{1} c_{1}(\mathbf{x}),
$$</p><p>and noting that $\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}, \lambda_{1}\right)=\nabla f(\mathbf{x})-\lambda_{1} \nabla c_{1}(\mathbf{x})$, we can state the condition \eqref{eq:parallel_gradients} equivalently as follows: At the solution $\mathbf{x}^{\star}$, there is a scalar $\lambda_{1}^{\star}$ such that</p><p>\begin{equation}
\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}^{\star}, \lambda_{1}^{\star}\right)=0.
\label{eq:lagrangian_gradient_zero}
\end{equation}</p><p>This observation suggests that we can search for solutions of the equality-constrained problem \eqref{eq:equality_example} by searching for stationary points of the Lagrangian function. The scalar quantity $\lambda_{1}$ is called a Lagrange multiplier for the constraint $c_{1}(\mathbf{x})=0$.</p><p>Though the condition \eqref{eq:parallel_gradients} (equivalently, \eqref{eq:lagrangian_gradient_zero}) appears to be necessary for an optimal solution of the problem \eqref{eq:equality_example}, it is clearly not sufficient. For instance, in this example, \eqref{eq:parallel_gradients} is satisfied at the point $\mathbf{x}=(1,1)$ (with $\lambda_{1}=\frac{1}{2}$ ), but this point is obviously not a solution-in fact, it maximizes the function $f$ on the circle. Moreover, in the case of equality-constrained problems, we cannot turn the condition \eqref{eq:parallel_gradients} into a sufficient condition simply by placing some restriction on the sign of $\lambda_{1}$. To see this, consider replacing the constraint $x_{1}^{2}+x_{2}^{2}-2=0$ by its negative $2-x_{1}^{2}-x_{2}^{2}=0$. The solution of the problem is not affected, but the value of $\lambda_{1}^{\star}$ that satisfies the condition \eqref{eq:parallel_gradients} changes from $\lambda_{1}^{\star}=-\frac{1}{2}$ to $\lambda_{1}^{\star}=\frac{1}{2}$.</p><p>This situation is illustrated in following visualization:</p><iframe style=border:none scrolling=no src=../../../../interactive/onesingle_constraint.html width=700px height=500px title="One single constraint"></iframe><h4 id=a-single-inequality-constraint>A single inequality constraint
<a class=anchor href=#a-single-inequality-constraint>#</a></h4><p><strong>Example 2</strong></p><p>This is a slight modification of Example 1, in which the equality constraint is replaced by an inequality. Consider</p><p>\begin{equation}
\min x_{1}+x_{2} \quad \text { s.t. } \quad 2-x_{1}^{2}-x_{2}^{2} \geq 0,
\label{eq:inequality_example}
\end{equation}</p><p>for which the feasible region consists of the circle of problem \eqref{eq:equality_example} and its interior. Note that the constraint normal $\nabla c_{1}$ points toward the interior of the feasible region at each point on the boundary of the circle. By inspection, we see that the solution is still $(-1,-1)$ and that the condition \eqref{eq:parallel_gradients} holds for the value $\lambda_{1}^{\star}=\frac{1}{2}$. However, this inequality-constrained problem differs from the equality-constrained problem \eqref{eq:equality_example} in that the sign of the Lagrange multiplier plays a significant role, as we now argue.</p><p>As before, we conjecture that a given feasible point $\mathbf{x}$ is not optimal if we can find a step $\mathbf{d}$ that both retains feasibility and decreases the objective function $f$ to first order. The main difference between problems \eqref{eq:equality_example} and \eqref{eq:inequality_example} comes in the handling of the feasibility condition. The direction $\mathbf{d}$ improves the objective function, to first order, if $\nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}&lt;0$. Meanwhile, the direction $\mathbf{d}$ retains feasibility if</p><p>$$
0 \leq c_{1}(\mathbf{x}+\mathbf{d}) \approx c_{1}(\mathbf{x})+\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d}
$$</p><p>so, to first order, feasibility is retained if</p><p>$$
c_{1}(\mathbf{x})+\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0
$$</p><p>In determining whether a direction $\mathbf{d}$ exists that satisfies both conditions, we consider the following two cases:</p><p><strong>Case I:</strong> Consider first the case in which $\mathbf{x}$ lies strictly inside the circle, so that the strict inequality $c_{1}(\mathbf{x})>0$ holds. In this case, any vector $\mathbf{d}$ satisfies the feasibility condition, provided only that its length is sufficiently small. In particular, whenever $\nabla f\left(\mathbf{x}^{\star}\right) \neq \mathbf{0}$, we can obtain a direction $\mathbf{d}$ that satisfies both conditions by setting</p><p>$$
\mathbf{d}=-c_{1}(\mathbf{x}) \frac{\nabla f(\mathbf{x})}{\|\nabla f(\mathbf{x})\|}
$$</p><p>The only situation in which such a direction fails to exist is when</p><p>$$
\nabla f(\mathbf{x})=\mathbf{0} .
$$</p><p><strong>Case II:</strong> Consider now the case in which $\mathbf{x}$ lies on the boundary of the circle, so that $c_{1}(\mathbf{x})=0$. The conditions therefore become</p><p>$$
\nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}&lt;0, \quad \nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0
$$</p><p>The first of these conditions defines an open half-space, while the second defines a closed half-space. It is clear that the two regions fail to intersect only when $\nabla f(\mathbf{x})$ and $\nabla c_{1}(\mathbf{x})$ point in the same direction, that is, when</p><p>\begin{equation}
\nabla f(\mathbf{x})=\lambda_{1} \nabla c_{1}(\mathbf{x}), \quad \text { for some } \lambda_{1} \geq 0.
\label{eq:inequality_optimality}
\end{equation}</p><p>Note that the sign of the multiplier is significant here. If \eqref{eq:parallel_gradients} were satisfied with a negative value of $\lambda_{1}$, then $\nabla f(\mathbf{x})$ and $\nabla c_{1}(\mathbf{x})$ would point in opposite directions, and we see that the set of directions that satisfy both conditions would make up an entire open half-plane.</p><p>The optimality conditions for both cases I and II can again be summarized neatly with reference to the Lagrangian function. When no first-order feasible descent direction exists at some point $\mathbf{x}^{\star}$, we have that</p><p>\begin{equation}
\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}^{\star}, \lambda_{1}^{\star}\right)=\mathbf{0}, \quad \text { for some } \lambda_{1}^{\star} \geq 0,
\label{eq:kkt_gradient}
\end{equation}</p><p>where we also require that</p><p>\begin{equation}
\lambda_{1}^{\star} c_{1}\left(\mathbf{x}^{\star}\right)=0.
\label{eq:complementarity}
\end{equation}</p><p>This condition is known as a complementarity condition; it implies that the Lagrange multiplier $\lambda_{1}$ can be strictly positive only when the corresponding constraint $c_{1}$ is active. Conditions of this type play a central role in constrained optimization, as we see in the sections that follow. In case I, we have that $c_{1}\left(\mathbf{x}^{\star}\right)>0$, so \eqref{eq:complementarity} requires that $\lambda_{1}^{\star}=0$. Hence, \eqref{eq:kkt_gradient} reduces to $\nabla f\left(\mathbf{x}^{\star}\right)=\mathbf{0}$, as required. In case II, \eqref{eq:complementarity} allows $\lambda_{1}^{\star}$ to take on a nonnegative value, so \eqref{eq:kkt_gradient} becomes equivalent to \eqref{eq:inequality_optimality}.</p><h2 id=two-inequality-constraints>Two inequality constraints
<a class=anchor href=#two-inequality-constraints>#</a></h2><p><strong>Example 3</strong></p><p>Suppose we add an extra constraint to the problem \eqref{eq:inequality_example} to obtain</p><p>\begin{equation}
\min x_{1}+x_{2} \quad \text { s.t. } \quad 2-x_{1}^{2}-x_{2}^{2} \geq 0, \quad x_{2} \geq 0,
\label{eq:two_inequality_example}
\end{equation}</p><p>for which the feasible region is the half-disk. It is easy to see that the solution lies at $(-\sqrt{2}, 0)^{\mathrm{T}}$, a point at which both constraints are active. By repeating the arguments for the previous examples, we conclude that a direction $\mathbf{d}$ is a feasible descent direction, to first order, if it satisfies the following conditions:</p><p>$$
\nabla c_{i}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0, \quad i \in \mathcal{I}=\{1,2\}, \quad \nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}&lt;0
$$</p><p>However, it is clear that no such direction can exist when $\mathbf{x}=(-\sqrt{2}, 0)^{\mathrm{T}}$. The conditions $\nabla c_{i}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0, i=1,2$, are both satisfied only if $\mathbf{d}$ lies in the quadrant defined by $\nabla c_{1}(\mathbf{x})$ and $\nabla c_{2}(\mathbf{x})$, but it is clear by inspection that all vectors $\mathbf{d}$ in this quadrant satisfy $\nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0$.</p><p>Let us see how the Lagrangian and its derivatives behave for the problem \eqref{eq:two_inequality_example} and the solution point $(-\sqrt{2}, 0)^{\mathrm{T}}$. First, we include an additional term $\lambda_{i} c_{i}(\mathbf{x})$ in the Lagrangian for each additional constraint, so we have</p><p>\begin{equation}
\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})=f(\mathbf{x})-\lambda_{1} c_{1}(\mathbf{x})-\lambda_{2} c_{2}(\mathbf{x}),
\label{eq:two_constraint_lagrangian}
\end{equation}</p><p>where $\boldsymbol{\lambda}=\left(\lambda_{1}, \lambda_{2}\right)^{\mathrm{T}}$ is the vector of Lagrange multipliers. The extension of condition \eqref{eq:kkt_gradient} to this case is</p><p>\begin{equation}
\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}^{\star}, \boldsymbol{\lambda}^{\star}\right)=\mathbf{0}, \quad \text { for some } \boldsymbol{\lambda}^{\star} \geq \mathbf{0},
\label{eq:two_constraint_kkt}
\end{equation}</p><p>where the inequality $\boldsymbol{\lambda}^{\star} \geq \mathbf{0}$ means that all components of $\boldsymbol{\lambda}^{\star}$ are required to be nonnegative. By applying the complementarity condition \eqref{eq:complementarity} to both inequality constraints, we obtain</p><p>\begin{equation}
\lambda_{1}^{\star} c_{1}\left(\mathbf{x}^{\star}\right)=0, \quad \lambda_{2}^{\star} c_{2}\left(\mathbf{x}^{\star}\right)=0.
\label{eq:two_constraint_complementarity}
\end{equation}</p><p>When $\mathbf{x}^{\star}=(-\sqrt{2}, 0)^{\mathrm{T}}$, we have</p><p>$$
\nabla f\left(\mathbf{x}^{\star}\right)=\begin{bmatrix} 1 \\ 1 \end{bmatrix}, \quad \nabla c_{1}\left(\mathbf{x}^{\star}\right)=\begin{bmatrix} 2 \sqrt{2} \\ 0 \end{bmatrix}, \quad \nabla c_{2}\left(\mathbf{x}^{\star}\right)=\begin{bmatrix} 0 \\ 1 \end{bmatrix},
$$</p><p>so that it is easy to verify that $\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}^{\star}, \boldsymbol{\lambda}^{\star}\right)=\mathbf{0}$ when we select $\boldsymbol{\lambda}^{\star}$ as follows:</p><p>$$
\boldsymbol{\lambda}^{\star}=\begin{bmatrix} 1 /(2 \sqrt{2}) \\ 1 \end{bmatrix}
$$</p><p>Note that both components of $\boldsymbol{\lambda}^{\star}$ are positive.</p><p>We consider now some other feasible points that are not solutions of \eqref{eq:two_inequality_example}, and examine the properties of the Lagrangian and its gradient at these points.</p><p>For the point $\mathbf{x}=(\sqrt{2}, 0)^{\mathrm{T}}$, we again have that both constraints are active. However, the objective gradient $\nabla f(\mathbf{x})$ no longer lies in the quadrant defined by the conditions $\nabla c_{i}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0, i=1,2$. One first-order feasible descent direction from this point-a vector $\mathbf{d}$ that satisfies the required conditions-is simply $\mathbf{d}=(-1,0)^{\mathrm{T}}$; there are many others. For this value of $\mathbf{x}$ it is easy to verify that the condition $\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})=\mathbf{0}$ is satisfied only when $\boldsymbol{\lambda}=(-1 /(2 \sqrt{2}), 1)$. Note that the first component $\lambda_{1}$ is negative, so that the conditions \eqref{eq:two_constraint_kkt} are not satisfied at this point.</p><p>Finally, let us consider the point $\mathbf{x}=(1,0)^{\mathrm{T}}$, at which only the second constraint $c_{2}$ is active. At this point, linearization of $f$ and $c$ gives the following conditions, which must be satisfied for $\mathbf{d}$ to be a feasible descent direction, to first order:</p><p>$$
1+\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0, \quad \nabla c_{2}(\mathbf{x})^{\mathrm{T}} \mathbf{d} \geq 0, \quad \nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}&lt;0 .
$$</p><p>In fact, we need worry only about satisfying the second and third conditions, since we can always satisfy the first condition by multiplying $\mathbf{d}$ by a sufficiently small positive quantity. By noting that</p><p>$
\nabla f(\mathbf{x})=\begin{bmatrix} 1 \\ 1 \end{bmatrix}, \quad \nabla c_{2}(\mathbf{x})=\begin{bmatrix} 0 \\ 1 \end{bmatrix}
$</p><p>it is easy to verify that the vector $\mathbf{d}=\left(-\frac{1}{2}, \frac{1}{4}\right)$ satisfies the required conditions and is therefore a descent direction.</p><p>To show that optimality conditions \eqref{eq:two_constraint_kkt} and \eqref{eq:two_constraint_complementarity} fail, we note first from \eqref{eq:two_constraint_complementarity} that since $c_{1}(\mathbf{x})>0$, we must have $\lambda_{1}=0$. Therefore, in trying to satisfy $\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})=\mathbf{0}$, we are left to search for a value $\lambda_{2}$ such that $\nabla f(\mathbf{x})-\lambda_{2} \nabla c_{2}(\mathbf{x})=\mathbf{0}$. No such $\lambda_{2}$ exists, and thus this point fails to satisfy the optimality conditions.</p><h3 id=first-order-optimality-conditions>First-order optimality conditions
<a class=anchor href=#first-order-optimality-conditions>#</a></h3><h2 id=statement-of-first-order-necessary-conditions>Statement of first-order necessary conditions
<a class=anchor href=#statement-of-first-order-necessary-conditions>#</a></h2><p>The three examples above suggest that a number of conditions are important in the characterization of solutions for the general problem. These include the relation $\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})=\mathbf{0}$, the nonnegativity of $\lambda_{i}$ for all inequality constraints $c_{i}(\mathbf{x})$, and the complementarity condition $\lambda_{i} c_{i}(\mathbf{x})=0$ that is required for all the inequality constraints. We now generalize the observations made in these examples and state the first-order optimality conditions in a rigorous fashion.</p><p>In general, the Lagrangian for the constrained optimization problem is defined as</p><p>\begin{equation}
\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})=f(\mathbf{x})-\sum_{i \in \mathcal{E} \cup \mathcal{I}} \lambda_{i} c_{i}(\mathbf{x}).
\label{eq:general_lagrangian}
\end{equation}</p><p>The active set $\mathcal{A}(\mathbf{x})$ at any feasible $\mathbf{x}$ is the union of the set $\mathcal{E}$ with the indices of the active inequality constraints; that is,</p><p>\begin{equation}
\mathcal{A}(\mathbf{x})=\mathcal{E} \cup\left\{i \in \mathcal{I} \mid c_{i}(\mathbf{x})=0\right\}.
\label{eq:active_set}
\end{equation}</p><p>Next, we need to give more attention to the properties of the constraint gradients. The vector $\nabla c_{i}(\mathbf{x})$ is often called the normal to the constraint $c_{i}$ at the point $\mathbf{x}$, because it is usually a vector that is perpendicular to the contours of the constraint $c_{i}$ at $\mathbf{x}$, and in the case of an inequality constraint, it points toward the feasible side of this constraint. It is possible, however, that $\nabla c_{i}(\mathbf{x})$ vanishes due to the algebraic representation of $c_{i}$, so that the term $\lambda_{i} \nabla c_{i}(\mathbf{x})$ vanishes for all values of $\lambda_{i}$ and does not play a role in the Lagrangian gradient $\nabla_{\mathbf{x}} \mathcal{L}$. For instance, if we replaced the constraint in \eqref{eq:equality_example} by the equivalent condition</p><p>$
c_{1}(\mathbf{x})=\left(x_{1}^{2}+x_{2}^{2}-2\right)^{2}=0
$</p><p>we would have that $\nabla c_{1}(\mathbf{x})=\mathbf{0}$ for all feasible points $\mathbf{x}$, and in particular that the condition $\nabla f(\mathbf{x})=\lambda_{1} \nabla c_{1}(\mathbf{x})$ no longer holds at the optimal point $(-1,-1)^{\mathrm{T}}$. We usually make an assumption called a constraint qualification to ensure that such degenerate behavior does not occur at the value of $\mathbf{x}$ in question. One such constraint qualification-probably the one most often used in the design of algorithms-is the one defined as follows:</p><div id=licq class=theorem-box><p class=theorem-title><strong>Definition 6.4 (Linear independence constraint qualification (LICQ))</strong></p><div class=theorem-content>Given the point $\mathbf{x}^{\star}$ and the active set $\mathcal{A}\left(\mathbf{x}^{\star}\right)$ defined by \eqref{eq:active_set}, we say that the <strong>linear independence constraint qualification (LICQ)</strong> holds if the set of active constraint gradients $\left\{\nabla c_{i}\left(\mathbf{x}^{\star}\right), i \in \mathcal{A}\left(\mathbf{x}^{\star}\right)\right\}$ is linearly independent.</div></div><p>Note that if this condition holds, none of the active constraint gradients can be zero.</p><p>This condition allows us to state the following optimality conditions for a general nonlinear programming problem. These conditions provide the foundation for many of the algorithms described in the remaining chapters of the lecture. They are called first-order conditions because they concern themselves with properties of the gradients (first-derivative vectors) of the objective and constraint functions.</p><div id=first_order_necessary class=theorem-box><p class=theorem-title><strong>Theorem 6.1 (First-order necessary conditions)</strong></p><div class=theorem-content><p>Suppose that $\mathbf{x}^{\star}$ is a local solution and that the LICQ holds at $\mathbf{x}^{\star}$. Then there is a Lagrange multiplier vector $\boldsymbol{\lambda}^{\star}$, with components $\lambda_{i}^{\star}, i \in \mathcal{E} \cup \mathcal{I}$, such that the following conditions are satisfied at $\left(\mathbf{x}^{\star}, \boldsymbol{\lambda}^{\star}\right)$:</p><p>\begin{align}
\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}^{\star}, \boldsymbol{\lambda}^{\star}\right)&=\mathbf{0}, \label{eq:kkt_gradient_zero} \\
c_{i}\left(\mathbf{x}^{\star}\right)&=0, \quad && \text { for all } i \in \mathcal{E}, \label{eq:kkt_equality} \\
c_{i}\left(\mathbf{x}^{\star}\right)&\geq 0, \quad && \text { for all } i \in \mathcal{I}, \label{eq:kkt_inequality} \\
\lambda_{i}^{\star} &\geq 0, \quad && \text { for all } i \in \mathcal{I}, \label{eq:kkt_multiplier_sign} \\
\lambda_{i}^{\star} c_{i}\left(\mathbf{x}^{\star}\right)&=0, \quad && \text { for all } i \in \mathcal{E} \cup \mathcal{I}. \label{eq:kkt_complementarity}
\end{align}</p></div></div><p>The conditions \eqref{eq:kkt_gradient_zero}-\eqref{eq:kkt_complementarity} are often known as the Karush-Kuhn-Tucker conditions, or KKT conditions for short. Because the complementarity condition implies that the Lagrange multipliers corresponding to inactive inequality constraints are zero, we can omit the terms for indices $i \notin \mathcal{A}\left(\mathbf{x}^{\star}\right)$ from \eqref{eq:kkt_gradient_zero} and rewrite this condition as</p><p>\begin{equation}
\mathbf{0}=\nabla_{\mathbf{x}} \mathcal{L}\left(\mathbf{x}^{\star}, \boldsymbol{\lambda}^{\star}\right)=\nabla f\left(\mathbf{x}^{\star}\right)-\sum_{i \in \mathcal{A}\left(\mathbf{x}^{\star}\right)} \lambda_{i}^{\star} \nabla c_{i}\left(\mathbf{x}^{\star}\right).
\label{eq:kkt_active_gradients}
\end{equation}</p><p>A special case of complementarity is important and deserves its own definition:</p><div id=strict_complementarity class=theorem-box><p class=theorem-title><strong>Definition 6.5 (Strict complementarity)</strong></p><div class=theorem-content>Given a local solution $\mathbf{x}^{\star}$ and a vector $\boldsymbol{\lambda}^{\star}$ satisfying \eqref{eq:kkt_gradient_zero}-\eqref{eq:kkt_complementarity}, we say that the <strong>strict complementarity condition</strong> holds if exactly one of $\lambda_{i}^{\star}$ and $c_{i}\left(\mathbf{x}^{\star}\right)$ is zero for each index $i \in \mathcal{I}$. In other words, we have that $\lambda_{i}^{\star}>0$ for each $i \in \mathcal{I} \cap \mathcal{A}\left(\mathbf{x}^{\star}\right)$.</div></div><p>For a given problem and solution point $\mathbf{x}^{\star}$, there may be many vectors $\boldsymbol{\lambda}^{\star}$ for which the conditions \eqref{eq:kkt_gradient_zero}-\eqref{eq:kkt_complementarity} are satisfied. When the LICQ holds, however, the optimal $\boldsymbol{\lambda}^{\star}$ is unique.</p><p><strong>Example 4</strong></p><p>Consider the feasible region described by the four constraints:</p><p>\begin{equation}
\min_{\mathbf{x}}\left(x_{1}-\frac{3}{2}\right)^{2}+\left(x_{2}-\frac{1}{8}\right)^{4} \quad \text { s.t. } \quad\begin{bmatrix} 1-x_{1}-x_{2} \\ 1-x_{1}+x_{2} \\ 1+x_{1}-x_{2} \\ 1+x_{1}+x_{2} \end{bmatrix} \geq \mathbf{0}.
\label{eq:diamond_example}
\end{equation}</p><p>It is fairly clear that the solution is $\mathbf{x}^{\star}=(1,0)$. The first and second constraints are active at this point. Denoting them by $c_{1}$ and $c_{2}$ (and the inactive constraints by $c_{3}$ and $c_{4}$ ), we have</p><p>$
\nabla f\left(\mathbf{x}^{\star}\right)=\begin{bmatrix} -1 \\ -\frac{1}{2} \end{bmatrix}, \quad \nabla c_{1}\left(\mathbf{x}^{\star}\right)=\begin{bmatrix} -1 \\ -1 \end{bmatrix}, \quad \nabla c_{2}\left(\mathbf{x}^{\star}\right)=\begin{bmatrix} -1 \\ 1 \end{bmatrix} .
$</p><p>Therefore, the KKT conditions \eqref{eq:kkt_gradient_zero}-\eqref{eq:kkt_complementarity} are satisfied when we set</p><p>$
\boldsymbol{\lambda}^{\star}=\left(\frac{3}{4}, \frac{1}{4}, 0,0\right)^{\mathrm{T}}.
$</p><p><strong>Exercises</strong></p><ol><li><p>For Example 1, verify that the direction $\mathbf{d}$ defined by
$\mathbf{d}=-\left(\mathbf{I}-\frac{\nabla c_{1}(\mathbf{x}) \nabla c_{1}(\mathbf{x})^{\mathrm{T}}}{\|\nabla c_{1}(\mathbf{x})\|^{2}}\right) \nabla f(\mathbf{x})$
satisfies both $\nabla c_{1}(\mathbf{x})^{\mathrm{T}} \mathbf{d}=0$ and $\nabla f(\mathbf{x})^{\mathrm{T}} \mathbf{d}&lt;0$, provided that $\nabla f(\mathbf{x})$ and $\nabla c_{1}(\mathbf{x})$ are not parallel.</p></li><li><p>For Example 3, find another first-order feasible descent direction from the point $\mathbf{x}=(\sqrt{2}, 0)^{\mathrm{T}}$, in addition to $\mathbf{d}=(-1,0)^{\mathrm{T}}$.</p></li><li><p>Show that when the LICQ holds at a KKT point $\mathbf{x}^{\star}$ for problem, the Lagrange multiplier vector $\boldsymbol{\lambda}^{\star}$ is uniquely defined.</p></li><li><p>Consider the problem
$\min x_{1}^{2}+x_{2}^{2} \quad \text{s.t.} \quad (x_{1}-1)^{3}-x_{2}^{2}=0.$</p><p>a) Sketch the feasible region and solve the problem geometrically.</p><p>b) Write down the KKT conditions and verify that they are satisfied at the solution you found in part (a).</p><p>c) Does the LICQ hold at the solution?</p></li><li><p>Consider the problem
$\min (x_{1}-2)^{2}+(x_{2}-1)^{2} \quad \text{s.t.} \quad x_{1}^{2}+x_{2}^{2} \leq 1, \quad x_{1}+x_{2} \geq 1.$</p><p>Find all points that satisfy the KKT conditions and identify which ones are local solutions.</p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#local-and-global-solutions>Local and global solutions</a></li><li><a href=#smoothness>Smoothness</a><ul><li><a href=#examples>Examples</a></li></ul></li><li><a href=#two-inequality-constraints>Two inequality constraints</a><ul><li><a href=#first-order-optimality-conditions>First-order optimality conditions</a></li></ul></li><li><a href=#statement-of-first-order-necessary-conditions>Statement of first-order necessary conditions</a></li></ul></nav></div></aside></main></body></html>