<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reminders on Numerical optimization</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/</link><description>Recent content in Reminders on Numerical optimization</description><generator>Hugo</generator><language>fr</language><atom:link href="http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/index.xml" rel="self" type="application/rss+xml"/><item><title>Linear Algebra</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/linear_algebra/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/linear_algebra/</guid><description>&lt;h1 id="fundamentals-of-linear-algebra">
 Fundamentals of Linear Algebra
 &lt;a class="anchor" href="#fundamentals-of-linear-algebra">#&lt;/a>
&lt;/h1>
&lt;h2 id="1---introduction">
 1 - Introduction
 &lt;a class="anchor" href="#1---introduction">#&lt;/a>
&lt;/h2>
&lt;blockquote>
&lt;p>Linear algebra is one of the foundational branches of mathematics, with applications spanning from engineering and computer science to economics and physics. This document is extracted from the textbook &lt;strong>Matrix Differential Calculus with Applications in Statistics and Econometrics&lt;/strong> from Jan R. Magnus; Heinz Neudecker, adapting the notations to the ones used in the lectures.&lt;/p>
&lt;/blockquote>
&lt;p>In this chapter, we summarize some of the well-known definitions and theorems of matrix algebra. Most of the theorems will be proved.&lt;/p></description></item><item><title>Differentiation</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/differentiation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/reminders/differentiation/</guid><description>&lt;h1 id="differentiation-in-multiple-dimensions">
 Differentiation in Multiple Dimensions
 &lt;a class="anchor" href="#differentiation-in-multiple-dimensions">#&lt;/a>
&lt;/h1>
&lt;h2 id="1---introduction">
 1 - Introduction
 &lt;a class="anchor" href="#1---introduction">#&lt;/a>
&lt;/h2>
&lt;blockquote>
&lt;p>Differentiation provides the mathematical framework for understanding how functions change locally. While single-variable calculus introduces derivatives, most applications require working with functions of multiple variables. This chapter extends differentiation concepts to multivariate and matrix-valued functions, building the tools needed for optimization and analysis in higher dimensions.&lt;/p>
&lt;/blockquote>
&lt;h2 id="2---monovariate-reminders">
 2 - Monovariate Reminders
 &lt;a class="anchor" href="#2---monovariate-reminders">#&lt;/a>
&lt;/h2>
&lt;h3 id="derivative-of-a-function">
 Derivative of a Function
 &lt;a class="anchor" href="#derivative-of-a-function">#&lt;/a>
&lt;/h3>










&lt;div id="derivative_definition" class="theorem-box">
 &lt;p class="theorem-title">&lt;strong>Definition 0.1 (Derivative)&lt;/strong>&lt;/p></description></item></channel></rss>