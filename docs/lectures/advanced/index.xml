<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>II - Advanced problems on Numerical optimization</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/</link><description>Recent content in II - Advanced problems on Numerical optimization</description><generator>Hugo</generator><language>fr</language><atom:link href="http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/index.xml" rel="self" type="application/rss+xml"/><item><title>1. Unconstrained optimization : Second-order</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/unconstrained_newton/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/unconstrained_newton/</guid><description>&lt;h1 id="unconstrained-optimization----second-order-methods">
 Unconstrained optimization - Second-order methods
 &lt;a class="anchor" href="#unconstrained-optimization----second-order-methods">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong> : This is in part the content of the book &amp;ldquo;Numerical Optimization&amp;rdquo; by Nocedal and Wright, with some modifications to the notations used in this lecture.&lt;/p>
&lt;/blockquote>
&lt;p>We have seen in the previous chapter that first-order methods, such as steepest descent, are often used to find a local minimum of a function $f(\mathbf{x})$. However, these methods can be slow to converge, especially when the function has ill-conditioned Hessian or when the initial guess is far from the solution. Second-order methods, which use information about the curvature of the function, can provide faster convergence rates.&lt;/p></description></item><item><title>2. Proximal methods</title><link>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/proximal_methods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://ammarmian.github.io/numerical_optimization/docs/lectures/advanced/proximal_methods/</guid><description>&lt;h1 id="proximal-methods">
 Proximal methods
 &lt;a class="anchor" href="#proximal-methods">#&lt;/a>
&lt;/h1>
&lt;p>We refer the reader to the monograph by &lt;a href="https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf">Parikh and Boyd (2014)&lt;/a> for a comprehensive overview of proximal methods.&lt;/p></description></item></channel></rss>