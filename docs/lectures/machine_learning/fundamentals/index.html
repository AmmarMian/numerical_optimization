<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Machine learning fundamentals through optimization
  #


Note: This lecture bridges our study of numerical optimization with machine learning, showing how the optimization techniques we&rsquo;ve developed provide the mathematical foundation for learning from data.


  Machine learning vs traditional programming
  #


  Traditional programming paradigm
  #

In traditional programming, we explicitly encode rules and logic to transform inputs into outputs. The paradigm follows a straightforward path: we receive input data, apply hand-crafted rules, and produce an output. This approach has served us well for many deterministic problems, but it encounters significant limitations when dealing with complex pattern recognition tasks."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/fundamentals/"><meta property="og:site_name" content="Numerical optimization"><meta property="og:title" content="1. Machine learning fundamentals"><meta property="og:description" content="Machine learning fundamentals through optimization # Note: This lecture bridges our study of numerical optimization with machine learning, showing how the optimization techniques weâ€™ve developed provide the mathematical foundation for learning from data.
Machine learning vs traditional programming # Traditional programming paradigm # In traditional programming, we explicitly encode rules and logic to transform inputs into outputs. The paradigm follows a straightforward path: we receive input data, apply hand-crafted rules, and produce an output. This approach has served us well for many deterministic problems, but it encounters significant limitations when dealing with complex pattern recognition tasks."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>1. Machine learning fundamentals | Numerical optimization</title>
<link rel=icon href=/numerical_optimization/favicon.png><link rel=manifest href=/numerical_optimization/manifest.json><link rel=canonical href=http://ammarmian.github.io/numerical_optimization/docs/lectures/machine_learning/fundamentals/><link rel=stylesheet href=/numerical_optimization/book.min.a8206ca0e1caaf803f4ef219929830ceb3f1ae72968a1975640344969b7a9c50.css integrity="sha256-qCBsoOHKr4A/TvIZkpgwzrPxrnKWihl1ZANElpt6nFA=" crossorigin=anonymous><script defer src=/numerical_optimization/fuse.min.js></script><script defer src=/numerical_optimization/en.search.min.0dba72d4127869e51d4b6b545ee71f5a8f542b09257511ec51863be50225be2b.js integrity="sha256-Dbpy1BJ4aeUdS2tUXucfWo9UKwkldRHsUYY75QIlvis=" crossorigin=anonymous></script><script>const chapterNum=0;MathJax={section:chapterNum,loader:{load:["[tex]/tagformat"]},tex:{packages:{"[+]":["tagformat"]},inlineMath:[["\\\\(","\\\\)"],["$","$"]],displayMath:[["\\[","\\]"],["$$","$$"]],processEnvironments:!0,processRefs:!0,tags:"ams",tagformat:{number:e=>MathJax.config.section+"."+e,id:e=>"eqn-id:"+e}},startup:{ready(){MathJax.startup.defaultReady(),MathJax.startup.input[0].preFilters.add(({math:e})=>{e.inputData.recompile&&(MathJax.config.section=e.inputData.recompile.section)}),MathJax.startup.input[0].postFilters.add(({math:e})=>{e.inputData.recompile&&(e.inputData.recompile.section=MathJax.config.section)})}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js defer></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/numerical_optimization/><span>Numerical optimization</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><a href=/numerical_optimization/docs/lectures/>Lectures</a><ul><li><a href=/numerical_optimization/docs/lectures/1_introduction/>Introduction</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/>I - Fundamentals</a><ul><li><a href=/numerical_optimization/docs/lectures/fundamentals/optimization_problems/>1. Optimization problems</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/>2. Unconstrained optimization : basics</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/convexity/>3. Convexity theory</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/>4. Unconstrained optimization : linesearch</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/>5. Constrained optimization - Introduction</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_projected/>5b. Constrained optimization - Projected Gradient Descent</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_optimization_linear/>6. Constrained optimization - Linear programming</a></li></ul></li><li><a href=/numerical_optimization/docs/lectures/advanced/>II - Advanced problems</a><ul><li><a href=/numerical_optimization/docs/lectures/advanced/unconstrained_newton/>1. Unconstrained optimization : Second-order</a></li><li><a href=/numerical_optimization/docs/lectures/advanced/proximal_methods/>2. Proximal methods</a></li></ul></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/>III - Machine Learning problems</a><ul><li><a href=/numerical_optimization/docs/lectures/machine_learning/fundamentals/ class=active>1. Machine learning fundamentals</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/svm/>2. Classification and support vector machines</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/neural_networks/>3. Neural Networks</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/modern/>4. Modern trends</a></li></ul></li><li><input type=checkbox id=section-28bd40dd904095dea2d407e437b9446e class=toggle>
<label for=section-28bd40dd904095dea2d407e437b9446e class="flex justify-between"><a href=/numerical_optimization/docs/lectures/reminders/>Reminders</a></label><ul><li><a href=/numerical_optimization/docs/lectures/reminders/linear_algebra/>Linear Algebra</a></li><li><a href=/numerical_optimization/docs/lectures/reminders/differentiation/>Differentiation</a></li></ul></li></ul></li><li class=book-section-flat><a href=/numerical_optimization/docs/practical_labs/>Practical labs</a><ul><li><a href=/numerical_optimization/docs/practical_labs/linear_regression/>I - Linear Regression models</a></li><li><a href=/numerical_optimization/docs/practical_labs/remote_sensing/>II - Remote Sensing Project</a></li><li><a href=/numerical_optimization/docs/practical_labs/mnist/>III - MNIST and Fashion-MNIST Classification</a></li><li><a href=/numerical_optimization/docs/practical_labs/environment/>Lab environment</a></li><li><a href=/numerical_optimization/docs/practical_labs/backtracking/>Backtracking memo</a></li><li><a href=/numerical_optimization/docs/practical_labs/quasinewton/>Quasi-Newton methods memo</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/numerical_optimization/svg/menu.svg class=book-icon alt=Menu></label><h3>1. Machine learning fundamentals</h3><label for=toc-control><img src=/numerical_optimization/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#machine-learning-vs-traditional-programming>Machine learning vs traditional programming</a><ul><li><a href=#traditional-programming-paradigm>Traditional programming paradigm</a></li><li><a href=#the-machine-learning-paradigm>The machine learning paradigm</a></li></ul></li><li><a href=#supervised-learning-setup>Supervised learning setup</a><ul><li><a href=#mathematical-formulation>Mathematical formulation</a></li><li><a href=#data-splitting-strategy>Data splitting strategy</a></li></ul></li><li><a href=#linear-and-polynomial-regression-revisited>Linear and polynomial regression revisited</a><ul><li><a href=#linear-regression-in-the-ml-framework>Linear regression in the ML framework</a></li><li><a href=#mean-squared-error-loss>Mean squared error loss</a></li><li><a href=#polynomial-regression-and-model-complexity>Polynomial regression and model complexity</a></li></ul></li><li><a href=#logistic-regression-for-classification>Logistic regression for classification</a><ul><li><a href=#why-not-linear-regression-for-classification>Why not linear regression for classification?</a></li><li><a href=#the-sigmoid-function>The sigmoid function</a></li><li><a href=#the-logistic-regression-model>The logistic regression model</a></li><li><a href=#maximum-likelihood-and-cross-entropy-loss>Maximum likelihood and cross-entropy loss</a></li><li><a href=#gradient-computation-for-logistic-regression>Gradient computation for logistic regression</a></li><li><a href=#connection-to-optimization-theory>Connection to optimization theory</a></li></ul></li><li><a href=#summary-and-next-steps>Summary and next steps</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=machine-learning-fundamentals-through-optimization>Machine learning fundamentals through optimization
<a class=anchor href=#machine-learning-fundamentals-through-optimization>#</a></h1><blockquote><p><strong>Note</strong>: This lecture bridges our study of numerical optimization with machine learning, showing how the optimization techniques we&rsquo;ve developed provide the mathematical foundation for learning from data.</p></blockquote><h2 id=machine-learning-vs-traditional-programming>Machine learning vs traditional programming
<a class=anchor href=#machine-learning-vs-traditional-programming>#</a></h2><h3 id=traditional-programming-paradigm>Traditional programming paradigm
<a class=anchor href=#traditional-programming-paradigm>#</a></h3><p>In traditional programming, we explicitly encode rules and logic to transform inputs into outputs. The paradigm follows a straightforward path: we receive input data, apply hand-crafted rules, and produce an output. This approach has served us well for many deterministic problems, but it encounters significant limitations when dealing with complex pattern recognition tasks.</p><p>Consider the challenge of face detection in images. A traditional approach might proceed as follows:</p><ol><li>Search for oval-shaped regions (potential head detection)</li><li>Within these regions, identify pairs of circular areas (eye candidates)</li><li>Apply Hough transform for edge detection</li><li>Manually tune thresholds for skin color detection</li><li>Handle edge cases explicitly (glasses, varying lighting, different angles)</li></ol><p>The code becomes increasingly complex as we attempt to handle more variations. Each new edge case requires additional rules, and the interactions between these rules can lead to brittle systems. More fundamentally, this approach requires the programmer to have deep domain expertise and the ability to explicitly articulate what constitutes a face in mathematical terms.</p><h3 id=the-machine-learning-paradigm>The machine learning paradigm
<a class=anchor href=#the-machine-learning-paradigm>#</a></h3><p>Machine learning fundamentally shifts this approach. Instead of programming explicit rules, we provide examples of inputs and their corresponding outputs, and let an algorithm learn the mapping between them. The paradigm becomes:</p><p>$$\text{Input Data} + \text{Labeled Examples} \rightarrow \text{Learning Algorithm} \rightarrow \text{Parametric Model } f_{\boldsymbol{\theta}}$$</p><p>The key mathematical framework underlying this approach consists of:</p><ul><li>A parametric function: $f_{\boldsymbol{\theta}}: \mathcal{X} \rightarrow \mathcal{Y}$</li><li>Parameters: $\boldsymbol{\theta} \in \mathbb{R}^p$</li><li>Learning as optimization: finding optimal $\boldsymbol{\theta}$ to minimize a loss function</li></ul><p>This shift brings several advantages. The system automatically learns patterns from data, naturally handles variations that appear in the training set, improves its performance with additional data, and generalizes to unseen cases that share similar patterns to the training data. The optimization perspective we&rsquo;ve developed in previous lectures becomes the engine that drives this learning process.</p><h2 id=supervised-learning-setup>Supervised learning setup
<a class=anchor href=#supervised-learning-setup>#</a></h2><h3 id=mathematical-formulation>Mathematical formulation
<a class=anchor href=#mathematical-formulation>#</a></h3><p>In supervised learning, we begin with a training dataset:</p><p>$$\mathcal{D} = \{(\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \ldots, (\mathbf{x}_n, y_n)\}$$</p><p>where each $\mathbf{x}_i \in \mathbb{R}^d$ represents the input features (such as pixel values for an image or measurements for a scientific experiment), and $y_i$ represents the corresponding output. For regression problems, $y_i \in \mathbb{R}$, while for classification problems, $y_i \in \{1, 2, \ldots, K\}$.</p><p>Our goal is to learn a function $f_{\boldsymbol{\theta}}: \mathbb{R}^d \rightarrow \mathcal{Y}$ that can accurately predict outputs for new, unseen inputs. This leads us to the core optimization problem of machine learning:</p><p>\begin{equation}
\boldsymbol{\theta}^{*} = \arg\min_{\boldsymbol{\theta}} \frac{1}{n} \sum_{i=1}^n L(f_{\boldsymbol{\theta}}(\mathbf{x}_i), y_i)
\label{eq:empirical_risk}
\end{equation}</p><p>where $L(\cdot, \cdot)$ is the loss function measuring prediction error. This formulation, known as empirical risk minimization, directly connects machine learning to the optimization techniques we&rsquo;ve studied. The choice of loss function $L$ and model family $f_{\boldsymbol{\theta}}$ determines the specific learning algorithm.</p><h3 id=data-splitting-strategy>Data splitting strategy
<a class=anchor href=#data-splitting-strategy>#</a></h3><p>A fundamental principle in machine learning is that we must evaluate our model on data it hasn&rsquo;t seen during training. This leads to the standard practice of splitting our data into three sets:</p><ul><li><strong>Training set (70-80%)</strong>: Used for parameter optimization via \eqref{eq:empirical_risk}</li><li><strong>Validation set (10-15%)</strong>: Used for hyperparameter tuning and model selection</li><li><strong>Test set (10-15%)</strong>: Used for final evaluationâ€”crucially, we never touch this set during development</li></ul><p>This splitting strategy addresses a key challenge: a model that perfectly memorizes the training data (achieving zero training loss) might perform poorly on new data. The validation set allows us to monitor this phenomenon and select models that generalize well.</p><h2 id=linear-and-polynomial-regression-revisited>Linear and polynomial regression revisited
<a class=anchor href=#linear-and-polynomial-regression-revisited>#</a></h2><h3 id=linear-regression-in-the-ml-framework>Linear regression in the ML framework
<a class=anchor href=#linear-regression-in-the-ml-framework>#</a></h3><p>Let&rsquo;s revisit linear regression from our optimization course, now viewing it through the machine learning lens. For the multivariate case, our model takes the form:</p><p>$$f_{\boldsymbol{\theta}}(\mathbf{x}) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \ldots + \theta_d x_d = \theta_0 + \boldsymbol{\theta}_{1:d}^{\mathrm{T}} \mathbf{x}$$</p><p>To simplify notation, we often augment the input vector with a 1 for the bias term, allowing us to write:</p><p>$$f_{\boldsymbol{\theta}}(\mathbf{x}) = \boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}$$</p><p>where now $\mathbf{x} = [1, x_1, x_2, \ldots, x_d]^{\mathrm{T}}$ and $\boldsymbol{\theta} = [\theta_0, \theta_1, \ldots, \theta_d]^{\mathrm{T}}$.</p><p>For the entire dataset, we can express predictions in matrix form:</p><p>$$\mathbf{f} = \mathbf{X}\boldsymbol{\theta}$$</p><p>where $\mathbf{X} \in \mathbb{R}^{n \times (d+1)}$ is the design matrix with each row being an augmented input vector.</p><h3 id=mean-squared-error-loss>Mean squared error loss
<a class=anchor href=#mean-squared-error-loss>#</a></h3><p>The mean squared error (MSE) loss function for linear regression is:</p><p>\begin{equation}
L(\boldsymbol{\theta}) = \frac{1}{2n} \sum_{i=1}^n (y_i - f_{\boldsymbol{\theta}}(\mathbf{x}_i))^2 = \frac{1}{2n} |\mathbf{y} - \mathbf{X}\boldsymbol{\theta}|^2
\label{eq:mse_loss}
\end{equation}</p><p>The factor of $\frac{1}{2}$ is a convenience that simplifies the derivative. Computing the gradient:</p><p>$$\nabla_{\boldsymbol{\theta}} L = \frac{1}{n} \mathbf{X}^{\mathrm{T}}(\mathbf{X}\boldsymbol{\theta} - \mathbf{y})$$</p><p>This leads to the gradient descent update rule:</p><p>$$\boldsymbol{\theta}^{(k+1)} = \boldsymbol{\theta}^{(k)} - \alpha \nabla_{\boldsymbol{\theta}} L = \boldsymbol{\theta}^{(k)} - \frac{\alpha}{n} \mathbf{X}^{\mathrm{T}}(\mathbf{X}\boldsymbol{\theta}^{(k)} - \mathbf{y})$$</p><p>Notice how this is exactly the optimization problem from our previous lectures, now applied to learning from data. The line search methods we studied for choosing $\alpha$ apply directly here.</p><h3 id=polynomial-regression-and-model-complexity>Polynomial regression and model complexity
<a class=anchor href=#polynomial-regression-and-model-complexity>#</a></h3><p>We can extend linear regression to capture nonlinear relationships by using polynomial features. For a single input variable $x$, we might use:</p><p>$$f_{\boldsymbol{\theta}}(x) = \theta_0 + \theta_1 x + \theta_2 x^2 + \ldots + \theta_p x^p$$</p><p>More generally, we can use any set of basis functions $\phi_j(x)$:</p><p>$$f_{\boldsymbol{\theta}}(\mathbf{x}) = \sum_{j=0}^p \theta_j \phi_j(\mathbf{x})$$</p><p>This remains linear in the parameters $\boldsymbol{\theta}$, so we can still use our linear regression machinery. However, increasing model complexity introduces a fundamental trade-off:</p><div id=bias_variance class=theorem-box><p class=theorem-title><strong>Definition 0.1 (Bias-variance trade-off)</strong></p><div class=theorem-content><strong>Underfitting</strong> occurs when the model is too simple to capture the underlying patterns (high bias, low variance). <strong>Overfitting</strong> occurs when the model memorizes the training data, including noise, leading to poor generalization (low bias, high variance). The goal is to find the optimal complexity that minimizes the total error on new data.</div></div><p>As we increase polynomial degree:</p><ul><li><strong>Degree 1 (linear)</strong>: May underfit if the true relationship is nonlinear</li><li><strong>Degree 2-4</strong>: Often captures real patterns well</li><li><strong>High degree (>10)</strong>: Risk of overfittingâ€”the model fits training data perfectly but generalizes poorly</li></ul><p>The validation set becomes crucial here: we monitor validation error as we increase model complexity and select the degree that minimizes validation error, not training error.</p><figure><img src=https://upload.wikimedia.org/wikipedia/commons/9/9f/Bias_and_variance_contributing_to_total_error.svg alt="Bias-variance trade-off" style=width:600px;margin:auto><figcaption>Bias-variance trade-off</figcaption></figure><h2 id=logistic-regression-for-classification>Logistic regression for classification
<a class=anchor href=#logistic-regression-for-classification>#</a></h2><p>Now that we&rsquo;ve established the foundations of linear regression, we turn to classification problems, where the output $y$ is categorical rather than continuous. The most common approach for binary classification is logistic regression.</p><h3 id=why-not-linear-regression-for-classification>Why not linear regression for classification?
<a class=anchor href=#why-not-linear-regression-for-classification>#</a></h3><p>For binary classification where $y \in \{0, 1\}$, we might initially consider using linear regression. However, this approach has several problems:</p><ol><li>Linear regression can output any real number, not just values in $[0,1]$</li><li>The loss function doesn&rsquo;t match the problemâ€”squared error penalizes &ldquo;very correct&rdquo; predictions</li><li>The model is sensitive to outliers in a way that doesn&rsquo;t make sense for classification</li></ol><p>We need a model that outputs probabilities and a loss function suited to classification.</p><h3 id=the-sigmoid-function>The sigmoid function
<a class=anchor href=#the-sigmoid-function>#</a></h3><p>The sigmoid (logistic) function transforms any real number to the interval $(0,1)$:</p><p>\begin{equation}
\sigma(z) = \frac{1}{1 + e^{-z}}
\label{eq:sigmoid}
\end{equation}</p><h3 id=the-logistic-regression-model>The logistic regression model
<a class=anchor href=#the-logistic-regression-model>#</a></h3><p>Logistic regression models the probability of the positive class as:</p><p>\begin{equation}
P(y=1|\mathbf{x}) = \sigma(\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}) = \frac{1}{1 + e^{-\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}}}
\label{eq:logistic_model}
\end{equation}</p><p>Correspondingly:
$$P(y=0|\mathbf{x}) = 1 - P(y=1|\mathbf{x}) = \frac{e^{-\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}}}{1 + e^{-\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}}}$$</p><p>For prediction, we typically use the decision rule:
$$\hat{y} = \begin{cases}
1 & \text{if } P(y=1|\mathbf{x}) > 0.5 \\
0 & \text{otherwise}
\end{cases}$$</p><p>This corresponds to the decision boundary $\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x} = 0$. Despite using a nonlinear sigmoid function, the decision boundary remains linear in the input spaceâ€”the sigmoid simply maps the linear function to probabilities.</p><h3 id=maximum-likelihood-and-cross-entropy-loss>Maximum likelihood and cross-entropy loss
<a class=anchor href=#maximum-likelihood-and-cross-entropy-loss>#</a></h3><p>To derive the appropriate loss function, we use the principle of maximum likelihood. For a single example, the likelihood is:</p><p>$$P(y|\mathbf{x}) = \sigma(\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x})^y \cdot (1-\sigma(\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}))^{1-y}$$</p><p>This compact expression gives $P(y=1|\mathbf{x})$ when $y=1$ and $P(y=0|\mathbf{x})$ when $y=0$.</p><p>Taking the negative log-likelihood over all training examples gives us the cross-entropy loss:</p><p>\begin{equation}
L(\boldsymbol{\theta}) = -\frac{1}{n} \sum_{i=1}^n \left[y_i \log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)\right]
\label{eq:cross_entropy}
\end{equation}</p><p>where $\hat{y}_i = \sigma(\boldsymbol{\theta}^{\mathrm{T}} \mathbf{x}_i)$.</p><h3 id=gradient-computation-for-logistic-regression>Gradient computation for logistic regression
<a class=anchor href=#gradient-computation-for-logistic-regression>#</a></h3><p>Computing the gradient of the cross-entropy loss yields a remarkably clean result. For the $j$-th component:</p><p>$$\frac{\partial L}{\partial \theta_j} = \frac{1}{n} \sum_{i=1}^n (\hat{y}_i - y_i) x_{i,j}$$</p><p>In vector form:
\begin{equation}
\nabla_{\boldsymbol{\theta}} L = \frac{1}{n} \mathbf{X}^{\mathrm{T}} (\hat{\mathbf{y}} - \mathbf{y})
\label{eq:logistic_gradient}
\end{equation}</p><p>This has exactly the same form as the gradient for linear regression! The only difference is that $\hat{\mathbf{y}}$ contains sigmoid-transformed predictions rather than linear predictions. This elegant connection shows how different loss functions and model choices lead to similar optimization structures.</p><h3 id=connection-to-optimization-theory>Connection to optimization theory
<a class=anchor href=#connection-to-optimization-theory>#</a></h3><p>Logistic regression loss is convex in $\boldsymbol{\theta}$, ensuring that any local minimum is a global minimum. The Hessian is:</p><p>$$\mathbf{H} = \frac{1}{n} \mathbf{X}^{\mathrm{T}} \mathbf{S} \mathbf{X}$$</p><p>where $\mathbf{S}$ is a diagonal matrix with $S_{ii} = \hat{y}_i(1-\hat{y}_i)$. Since $\hat{y}_i \in (0,1)$, all diagonal elements are positive, making $\mathbf{H}$ positive semi-definite. This connects directly to the second-order sufficient conditions for optimality from our previous lectures.</p><h2 id=summary-and-next-steps>Summary and next steps
<a class=anchor href=#summary-and-next-steps>#</a></h2><p>We&rsquo;ve seen how machine learning problems naturally formulate as optimization problems. Linear regression minimizes squared error, while logistic regression maximizes likelihood (minimizes cross-entropy). Both lead to optimization problems solvable with the gradient-based methods from our previous lectures.</p><p>In the next lecture, we&rsquo;ll explore how to scale these methods to massive datasets through stochastic gradient descent and its variants, connecting to the convergence theory and step size selection strategies we&rsquo;ve already developed.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#machine-learning-vs-traditional-programming>Machine learning vs traditional programming</a><ul><li><a href=#traditional-programming-paradigm>Traditional programming paradigm</a></li><li><a href=#the-machine-learning-paradigm>The machine learning paradigm</a></li></ul></li><li><a href=#supervised-learning-setup>Supervised learning setup</a><ul><li><a href=#mathematical-formulation>Mathematical formulation</a></li><li><a href=#data-splitting-strategy>Data splitting strategy</a></li></ul></li><li><a href=#linear-and-polynomial-regression-revisited>Linear and polynomial regression revisited</a><ul><li><a href=#linear-regression-in-the-ml-framework>Linear regression in the ML framework</a></li><li><a href=#mean-squared-error-loss>Mean squared error loss</a></li><li><a href=#polynomial-regression-and-model-complexity>Polynomial regression and model complexity</a></li></ul></li><li><a href=#logistic-regression-for-classification>Logistic regression for classification</a><ul><li><a href=#why-not-linear-regression-for-classification>Why not linear regression for classification?</a></li><li><a href=#the-sigmoid-function>The sigmoid function</a></li><li><a href=#the-logistic-regression-model>The logistic regression model</a></li><li><a href=#maximum-likelihood-and-cross-entropy-loss>Maximum likelihood and cross-entropy loss</a></li><li><a href=#gradient-computation-for-logistic-regression>Gradient computation for logistic regression</a></li><li><a href=#connection-to-optimization-theory>Connection to optimization theory</a></li></ul></li><li><a href=#summary-and-next-steps>Summary and next steps</a></li></ul></nav></div></aside></main></body></html>