<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  MNIST and Fashion-MNIST Classification
  #


  Introduction
  #

In this lab session, we explore handwritten digit recognition using the MNIST dataset, progressing from classical machine learning approaches to modern deep learning techniques. We then apply transfer learning to the more challenging Fashion-MNIST dataset. This progression mirrors the historical development of the field while providing hands-on experience with key optimization concepts.
The session is divided into three parts:

Part I: Classical approaches using Multi-Layer Perceptrons (MLP) and Support Vector Machines (SVM)
Part II: Deep learning with Convolutional Neural Networks (CNN)
Part III: Transfer learning applied to Fashion-MNIST


Note: For this lab you will need a running Python with packages: numpy, matplotlib, scikit-learn, pandase, torch, torchvision."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://ammarmian.github.io/numerical_optimization/docs/practical_labs/mnist/"><meta property="og:site_name" content="Numerical optimization"><meta property="og:title" content="III - MNIST and Fashion-MNIST Classification"><meta property="og:description" content="MNIST and Fashion-MNIST Classification # Introduction # In this lab session, we explore handwritten digit recognition using the MNIST dataset, progressing from classical machine learning approaches to modern deep learning techniques. We then apply transfer learning to the more challenging Fashion-MNIST dataset. This progression mirrors the historical development of the field while providing hands-on experience with key optimization concepts.
The session is divided into three parts:
Part I: Classical approaches using Multi-Layer Perceptrons (MLP) and Support Vector Machines (SVM) Part II: Deep learning with Convolutional Neural Networks (CNN) Part III: Transfer learning applied to Fashion-MNIST Note: For this lab you will need a running Python with packages: numpy, matplotlib, scikit-learn, pandase, torch, torchvision."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>III - MNIST and Fashion-MNIST Classification | Numerical optimization</title>
<link rel=icon href=/numerical_optimization/favicon.png><link rel=manifest href=/numerical_optimization/manifest.json><link rel=canonical href=http://ammarmian.github.io/numerical_optimization/docs/practical_labs/mnist/><link rel=stylesheet href=/numerical_optimization/book.min.a8206ca0e1caaf803f4ef219929830ceb3f1ae72968a1975640344969b7a9c50.css integrity="sha256-qCBsoOHKr4A/TvIZkpgwzrPxrnKWihl1ZANElpt6nFA=" crossorigin=anonymous><script defer src=/numerical_optimization/fuse.min.js></script><script defer src=/numerical_optimization/en.search.min.6698db5ec0b50ada94dfb50e4977481fdc66b0a9d0e104277817f19b95d6da6f.js integrity="sha256-ZpjbXsC1CtqU37UOSXdIH9xmsKnQ4QQneBfxm5XW2m8=" crossorigin=anonymous></script><script>const chapterNum=0;MathJax={section:chapterNum,loader:{load:["[tex]/tagformat"]},tex:{packages:{"[+]":["tagformat"]},inlineMath:[["\\\\(","\\\\)"],["$","$"]],displayMath:[["\\[","\\]"],["$$","$$"]],processEnvironments:!0,processRefs:!0,tags:"ams",tagformat:{number:e=>MathJax.config.section+"."+e,id:e=>"eqn-id:"+e}},startup:{ready(){MathJax.startup.defaultReady(),MathJax.startup.input[0].preFilters.add(({math:e})=>{e.inputData.recompile&&(MathJax.config.section=e.inputData.recompile.section)}),MathJax.startup.input[0].postFilters.add(({math:e})=>{e.inputData.recompile&&(e.inputData.recompile.section=MathJax.config.section)})}},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js defer></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/numerical_optimization/><span>Numerical optimization</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><a href=/numerical_optimization/docs/lectures/>Lectures</a><ul><li><a href=/numerical_optimization/docs/lectures/1_introduction/>Introduction</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/>I - Fundamentals</a><ul><li><a href=/numerical_optimization/docs/lectures/fundamentals/optimization_problems/>1. Optimization problems</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/unconstrained_optimization/>2. Unconstrained optimization : basics</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/convexity/>3. Convexity theory</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/unconstrained_linesearch/>4. Unconstrained optimization : linesearch</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_optimisation/>5. Constrained optimization - Introduction</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_projected/>5b. Constrained optimization - Projected Gradient Descent</a></li><li><a href=/numerical_optimization/docs/lectures/fundamentals/constrained_optimization_linear/>6. Constrained optimization - Linear programming</a></li></ul></li><li><a href=/numerical_optimization/docs/lectures/advanced/>II - Advanced problems</a><ul><li><a href=/numerical_optimization/docs/lectures/advanced/unconstrained_newton/>1. Unconstrained optimization : Second-order</a></li><li><a href=/numerical_optimization/docs/lectures/advanced/proximal_methods/>2. Proximal methods</a></li></ul></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/>III - Machine Learning problems</a><ul><li><a href=/numerical_optimization/docs/lectures/machine_learning/fundamentals/>1. Machine learning fundamentals</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/svm/>2. Classification and support vector machines</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/neural_networks/>3. Neural Networks</a></li><li><a href=/numerical_optimization/docs/lectures/machine_learning/modern/>4. Modern trends</a></li></ul></li><li><input type=checkbox id=section-28bd40dd904095dea2d407e437b9446e class=toggle>
<label for=section-28bd40dd904095dea2d407e437b9446e class="flex justify-between"><a href=/numerical_optimization/docs/lectures/reminders/>Reminders</a></label><ul><li><a href=/numerical_optimization/docs/lectures/reminders/linear_algebra/>Linear Algebra</a></li><li><a href=/numerical_optimization/docs/lectures/reminders/differentiation/>Differentiation</a></li></ul></li></ul></li><li class=book-section-flat><a href=/numerical_optimization/docs/practical_labs/>Practical labs</a><ul><li><a href=/numerical_optimization/docs/practical_labs/linear_regression/>I - Linear Regression models</a></li><li><a href=/numerical_optimization/docs/practical_labs/remote_sensing/>II - Remote Sensing Project</a></li><li><a href=/numerical_optimization/docs/practical_labs/mnist/ class=active>III - MNIST and Fashion-MNIST Classification</a></li><li><a href=/numerical_optimization/docs/practical_labs/environment/>Lab environment</a></li><li><a href=/numerical_optimization/docs/practical_labs/backtracking/>Backtracking memo</a></li><li><a href=/numerical_optimization/docs/practical_labs/quasinewton/>Quasi-Newton methods memo</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/numerical_optimization/svg/menu.svg class=book-icon alt=Menu></label><h3>III - MNIST and Fashion-MNIST Classification</h3><label for=toc-control><img src=/numerical_optimization/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#learning-objectives>Learning objectives</a></li><li><a href=#part-i-classical-machine-learning-approaches>Part I: Classical Machine Learning Approaches</a><ul><li><a href=#1-introduction-and-data-exploration>1. Introduction and Data Exploration</a></li><li><a href=#2-data-preprocessing-and-visualization>2. Data Preprocessing and Visualization</a></li><li><a href=#3-experimental-methodology>3. Experimental Methodology</a></li><li><a href=#4-multi-layer-perceptron-from-scratch>4. Multi-Layer Perceptron from Scratch</a></li><li><a href=#5-support-vector-machines>5. Support Vector Machines</a></li><li><a href=#6-comparative-analysis>6. Comparative Analysis</a></li></ul></li><li><a href=#part-ii-deep-learning-with-cnns>Part II: Deep Learning with CNNs</a><ul><li><a href=#1-transition-to-pytorch>1. Transition to PyTorch</a></li><li><a href=#2-convolutional-neural-network-design>2. Convolutional Neural Network Design</a></li><li><a href=#3-training-methodology>3. Training Methodology</a></li><li><a href=#4-advanced-optimization-strategies>4. Advanced Optimization Strategies</a></li></ul></li><li><a href=#part-iii-transfer-learning-with-fashion-mnist>Part III: Transfer Learning with Fashion-MNIST</a><ul><li><a href=#1-fashion-mnist-introduction>1. Fashion-MNIST Introduction</a></li><li><a href=#2-practical-implementation>2. Practical Implementation</a></li><li><a href=#4-comparative-analysis>4. Comparative Analysis</a></li><li><a href=#exercises-for-further-practice>Exercises for Further Practice</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=mnist-and-fashion-mnist-classification>MNIST and Fashion-MNIST Classification
<a class=anchor href=#mnist-and-fashion-mnist-classification>#</a></h1><h2 id=introduction>Introduction
<a class=anchor href=#introduction>#</a></h2><p>In this lab session, we explore handwritten digit recognition using the MNIST dataset, progressing from classical machine learning approaches to modern deep learning techniques. We then apply transfer learning to the more challenging Fashion-MNIST dataset. This progression mirrors the historical development of the field while providing hands-on experience with key optimization concepts.</p><p>The session is divided into three parts:</p><ul><li><strong>Part I</strong>: Classical approaches using Multi-Layer Perceptrons (MLP) and Support Vector Machines (SVM)</li><li><strong>Part II</strong>: Deep learning with Convolutional Neural Networks (CNN)</li><li><strong>Part III</strong>: Transfer learning applied to Fashion-MNIST</li></ul><blockquote><p><strong>Note:</strong> For this lab you will need a running Python with packages: <code>numpy</code>, <code>matplotlib</code>, <code>scikit-learn</code>, <code>pandase</code>, <code>torch</code>, <code>torchvision</code>.</p></blockquote><h2 id=learning-objectives>Learning objectives
<a class=anchor href=#learning-objectives>#</a></h2><p>By the end of this session, you should be able to:</p><ul><li>Implement backpropagation and stochastic gradient descent from scratch</li><li>Design proper validation strategies to avoid overfitting</li><li>Build and train CNNs using PyTorch</li><li>Apply transfer learning to improve model performance</li><li>Understand the trade-offs between different optimization strategies</li></ul><blockquote><p>You need to implement a backpropagation procedure for MLP. Since we didn&rsquo;t have time to cover this, we refer to <a href=https://visionbook.mit.edu/backpropagation.html>this ressource</a>.</p></blockquote><blockquote><p>A solution to this lab is available <a href=https://github.com/AmmarMian/MNIST_lab>here</a> but don&rsquo;t just look at it! Try to implement the code yourself first, and then compare your solution with the provided one.</p></blockquote><h2 id=part-i-classical-machine-learning-approaches>Part I: Classical Machine Learning Approaches
<a class=anchor href=#part-i-classical-machine-learning-approaches>#</a></h2><h3 id=1-introduction-and-data-exploration>1. Introduction and Data Exploration
<a class=anchor href=#1-introduction-and-data-exploration>#</a></h3><p>The MNIST dataset consists of 70,000 grayscale images of handwritten digits (0-9), each of size 28Ã—28 pixels. We begin by loading and exploring this dataset. This initial setup is provided for you.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> fetch_openml
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load MNIST data</span>
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> fetch_openml(<span style=color:#e6db74>&#39;mnist_784&#39;</span>, version<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, return_X_y<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, as_frame<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, parser<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Convert to appropriate types</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>int64)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Data shape: </span><span style=color:#e6db74>{</span>X<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Labels shape: </span><span style=color:#e6db74>{</span>y<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Number of classes: </span><span style=color:#e6db74>{</span>len(np<span style=color:#f92672>.</span>unique(y))<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Pixel value range: [</span><span style=color:#e6db74>{</span>X<span style=color:#f92672>.</span>min()<span style=color:#e6db74>}</span><span style=color:#e6db74>, </span><span style=color:#e6db74>{</span>X<span style=color:#f92672>.</span>max()<span style=color:#e6db74>}</span><span style=color:#e6db74>]&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Visualize some examples</span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>4</span>))
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, ax <span style=color:#f92672>in</span> enumerate(axes<span style=color:#f92672>.</span>flat):
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>imshow(X[i]<span style=color:#f92672>.</span>reshape(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Label: </span><span style=color:#e6db74>{</span>y[i]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p>For classical machine learning approaches, we work with flattened vectors rather than 2D images. Each image becomes a 784-dimensional vector where spatial structure is implicit in the feature ordering.</p><h3 id=2-data-preprocessing-and-visualization>2. Data Preprocessing and Visualization
<a class=anchor href=#2-data-preprocessing-and-visualization>#</a></h3><p>Preprocessing is crucial for optimization convergence. We&rsquo;ll normalize the data and use dimensionality reduction for visualization.</p><h4 id=normalization>Normalization
<a class=anchor href=#normalization>#</a></h4><p>Normalization ensures that all features contribute equally to the optimization process. For pixel values in range [0, 255], we have two main approaches:</p><ol><li><strong>Min-Max scaling</strong>: $x_{\text{scaled}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}} = \frac{x}{255}$</li><li><strong>Standardization</strong>: $x_{\text{std}} = \frac{x - \mu}{\sigma}$</li></ol><p>where $\mu$ is the mean and $\sigma$ is the standard deviation across the training set. We will use Min-Max scaling. The three-way data split (train, validation, test) is also performed here.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># We&#39;ll use MinMaxScaler for pixel data as it preserves the 0 boundary</span>
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> MinMaxScaler()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create a three-way split for robust evaluation</span>
</span></span><span style=display:flex><span>X_train, X_temp, y_train, y_temp <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.3</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>, stratify<span style=color:#f92672>=</span>y
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>X_val, X_test, y_val, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    X_temp, y_temp, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>, stratify<span style=color:#f92672>=</span>y_temp
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit scaler on training data only to avoid data leakage</span>
</span></span><span style=display:flex><span>X_train_scaled <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(X_train)
</span></span><span style=display:flex><span>X_val_scaled <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(X_val)
</span></span><span style=display:flex><span>X_test_scaled <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Training set: </span><span style=color:#e6db74>{</span>X_train_scaled<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Validation set: </span><span style=color:#e6db74>{</span>X_val_scaled<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test set: </span><span style=color:#e6db74>{</span>X_test_scaled<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=dimensionality-reduction-for-visualization>Dimensionality Reduction for Visualization
<a class=anchor href=#dimensionality-reduction-for-visualization>#</a></h4><p>To understand the data structure, we apply PCA and t-SNE. PCA finds the directions of maximum variance through eigenvalue decomposition of the covariance matrix: $\mathbf{C} = \frac{1}{n-1}\mathbf{X}^T\mathbf{X}$. The following code will help you visualize the high-dimensional data in 2D.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.decomposition <span style=color:#f92672>import</span> PCA
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.manifold <span style=color:#f92672>import</span> TSNE
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Apply PCA for visualization</span>
</span></span><span style=display:flex><span>pca <span style=color:#f92672>=</span> PCA(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>X_train_pca <span style=color:#f92672>=</span> pca<span style=color:#f92672>.</span>fit_transform(X_train_scaled)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># t-SNE for 2D visualization (on a subset for speed)</span>
</span></span><span style=display:flex><span>subset_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>5000</span>
</span></span><span style=display:flex><span>indices <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>choice(len(X_train_scaled), subset_size, replace<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>X_subset <span style=color:#f92672>=</span> X_train_scaled[indices]
</span></span><span style=display:flex><span>y_subset <span style=color:#f92672>=</span> y_train[indices]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tsne <span style=color:#f92672>=</span> TSNE(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>, perplexity<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>)
</span></span><span style=display:flex><span>X_tsne <span style=color:#f92672>=</span> tsne<span style=color:#f92672>.</span>fit_transform(X_subset)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Visualize t-SNE embedding</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>8</span>))
</span></span><span style=display:flex><span>scatter <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>scatter(X_tsne[:, <span style=color:#ae81ff>0</span>], X_tsne[:, <span style=color:#ae81ff>1</span>], c<span style=color:#f92672>=</span>y_subset, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;tab10&#39;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>colorbar(scatter)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;t-SNE visualization of MNIST digits&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;t-SNE component 1&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;t-SNE component 2&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h3 id=3-experimental-methodology>3. Experimental Methodology
<a class=anchor href=#3-experimental-methodology>#</a></h3><p>A rigorous experimental protocol is key to reliable results.</p><h4 id=three-way-data-splitting>Three-way Data Splitting
<a class=anchor href=#three-way-data-splitting>#</a></h4><p>We use a three-way split:</p><ul><li><strong>Training set (49,000 samples)</strong>: For model parameter learning.</li><li><strong>Validation set (10,500 samples)</strong>: For hyperparameter tuning and early stopping.</li><li><strong>Test set (10,500 samples)</strong>: For final, unbiased model evaluation.</li></ul><h4 id=k-fold-cross-validation>K-Fold Cross-Validation
<a class=anchor href=#k-fold-cross-validation>#</a></h4><p>For hyperparameter optimization, we employ K-fold cross-validation on the training set. The cross-validation error is:
$$\text{CV}(k) = \frac{1}{k} \sum_{i=1}^{k} L(\mathbf{w}_{-i}, \mathcal{D}_i)$$
where $\mathbf{w}_{-i}$ is the model trained on all folds except fold $i$.</p><h3 id=4-multi-layer-perceptron-from-scratch>4. Multi-Layer Perceptron from Scratch
<a class=anchor href=#4-multi-layer-perceptron-from-scratch>#</a></h3><p>Now for the main challenge: implementing a two-layer neural network from scratch to understand backpropagation and stochastic optimization.</p><h4 id=network-architecture>Network Architecture
<a class=anchor href=#network-architecture>#</a></h4><ul><li>Input layer: 784 neurons</li><li>Hidden layer: 128 neurons with ReLU activation</li><li>Output layer: 10 neurons with softmax activation</li></ul><p>The forward propagation equations are:
\begin{align}
\mathbf{z}^{(1)} &= \mathbf{W}^{(1)}\mathbf{x} + \mathbf{b}^{(1)} \\
\mathbf{a}^{(1)} &= \text{ReLU}(\mathbf{z}^{(1)}) \\
\mathbf{z}^{(2)} &= \mathbf{W}^{(2)}\mathbf{a}^{(1)} + \mathbf{b}^{(2)} \\
\hat{\mathbf{y}} &= \text{softmax}(\mathbf{z}^{(2)})
\end{align}</p><h4 id=loss-function>Loss Function
<a class=anchor href=#loss-function>#</a></h4><p>We use the cross-entropy loss:
$$L(\mathbf{W}, \mathbf{b}) = -\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{10} y_{ij}\log(\hat{y}_{ij})$$</p><h4 id=backpropagation-derivation>Backpropagation Derivation
<a class=anchor href=#backpropagation-derivation>#</a></h4><p>Here are the crucial gradients you&rsquo;ll need for implementation:</p><ol><li><strong>Output layer gradients</strong>: $\frac{\partial L}{\partial \mathbf{z}^{(2)}} = \hat{\mathbf{y}} - \mathbf{y}$</li><li><strong>Hidden layer gradients</strong>: $\frac{\partial L}{\partial \mathbf{z}^{(1)}} = (\mathbf{W}^{(2)})^T \frac{\partial L}{\partial \mathbf{z}^{(2)}} \odot \mathbf{1}[\mathbf{z}^{(1)} > 0]$</li><li><strong>Weight gradients</strong>:
$\frac{\partial L}{\partial \mathbf{W}^{(2)}} = \frac{1}{n}\sum_{i=1}^{n} \frac{\partial L}{\partial \mathbf{z}^{(2)}_i} (\mathbf{a}^{(1)}_i)^T$
and
$\frac{\partial L}{\partial \mathbf{W}^{(1)}} = \frac{1}{n}\sum_{i=1}^{n} \frac{\partial L}{\partial \mathbf{z}^{(1)}_i} \mathbf{x}_i^T$</li></ol><h4 id=implementation>Implementation
<a class=anchor href=#implementation>#</a></h4><p><strong>Task: Implement the <code>MLPFromScratch</code> Class</strong></p><p>Your task is to create a Python class <code>MLPFromScratch</code> that builds and trains our two-layer neural network. Use the information to guide you through implementing each method.</p><ol><li><strong>init</strong> & Helpers
<strong><code>__init__(self, ...)</code></strong></li></ol><ul><li>Initialize weights and biases for both layers. Use Xavier initialization for weights (e.g., <code>np.random.randn(...) * np.sqrt(2.0 / n_input)</code>) to aid convergence. Initialize biases to zero.</li><li>Initialize velocity terms for momentum-based gradient descent (e.g., <code>self.vW1</code>, <code>self.vb1</code>) as zero arrays with the same shape as the corresponding parameters.</li></ul><p><strong>Helper Functions</strong></p><ul><li><code>relu(self, x)</code>: Implement the ReLU activation function, $\max(0, x)$.</li><li><code>relu_derivative(self, x)</code>: Return 1 for positive inputs, 0 otherwise.</li><li><code>softmax(self, x)</code>: Implement the softmax function. Remember to subtract the max value from <code>x</code> before exponentiating for numerical stability: $\text{softmax}(\mathbf{z})_i = \frac{\exp(z_i - \max(\mathbf{z}))}{\sum_j \exp(z_j - \max(\mathbf{z}))}$.</li></ul><ol start=2><li>Forward Pass
<strong><code>forward(self, X)</code></strong></li></ol><ul><li>Implement the forward pass using the equations above.</li><li>The input <code>X</code> will have shape <code>(n_samples, n_features)</code>. It&rsquo;s often easier to work with column vectors, so you might need to transpose it.</li><li>Store intermediate values like <code>self.z1</code>, <code>self.a1</code>, <code>self.z2</code>, and <code>self.a2</code> as they are needed for backpropagation.</li><li>The method should return the final predictions, <code>a2</code>, transposed back to shape <code>(n_samples, n_classes)</code>.</li></ul><p><strong><code>compute_loss(self, y_pred, y_true)</code></strong></p><ul><li>Implement the cross-entropy loss.</li><li>You will need to convert the true labels <code>y_true</code> (e.g., <code>[5, 0, 4, ...]</code>) into one-hot encoded vectors.</li><li>Add a small epsilon (e.g., <code>1e-8</code>) to <code>y_pred</code> before taking the logarithm to avoid <code>log(0)</code>.</li></ul><ol start=3><li>Backward Pass
<strong><code>backward(self, X, y_true, momentum=0.9)</code></strong></li></ol><ul><li>This is the core of the learning process. Implement the backpropagation algorithm using the gradient equations provided.</li><li>Calculate the gradients for <code>W2</code>, <code>b2</code>, <code>W1</code>, and <code>b1</code>.</li><li>Update the velocity terms for each parameter using the momentum formula: $v_t = \text{momentum} \cdot v_{t-1} - \text{lr} \cdot \nabla L$.</li><li>Update the weights and biases using their corresponding velocity terms: $W \leftarrow W + v_W$.</li></ul><ol start=4><li>Train & Predict
<strong><code>train(self, X_train, y_train, ...)</code></strong></li></ol><ul><li>Implement the main training loop.</li><li>Iterate for a given number of <code>epochs</code>.</li><li>In each epoch, shuffle the training data to ensure batches are random.</li><li>Implement mini-batch gradient descent: loop through the training data in batches of a specified <code>batch_size</code>.</li><li>For each batch, perform a <code>forward</code> pass, <code>compute_loss</code>, and a <code>backward</code> pass.</li><li>After each epoch, calculate and store the training loss and the accuracy on the validation set. This allows you to monitor for overfitting.</li></ul><p><strong><code>predict(self, X)</code></strong></p><ul><li>Perform a forward pass and return the index of the highest-scoring class for each input sample using <code>np.argmax</code>.</li></ul><h4 id=training-the-mlp>Training the MLP
<a class=anchor href=#training-the-mlp>#</a></h4><p>Once your class is implemented, use the following code to train it and visualize the results. Experiment with different learning rates.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># NOTE: This code assumes you have created the MLPFromScratch class.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># mlp = MLPFromScratch(learning_rate=0.01)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># train_losses, val_accuracies = mlp.train(</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     X_train_scaled, y_train,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     X_val_scaled, y_val,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     epochs=50, batch_size=128</span>
</span></span><span style=display:flex><span><span style=color:#75715e># )</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Plot training curves</span>
</span></span><span style=display:flex><span><span style=color:#75715e># fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ax1.plot(train_losses)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ax1.set_xlabel(&#39;Epoch&#39;); ax1.set_ylabel(&#39;Training Loss&#39;); ax1.set_title(&#39;Training Loss over Epochs&#39;)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ax2.plot(val_accuracies)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ax2.set_xlabel(&#39;Epoch&#39;); ax2.set_ylabel(&#39;Validation Accuracy&#39;); ax2.set_title(&#39;Validation Accuracy over Epochs&#39;)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># plt.tight_layout(); plt.show()</span>
</span></span></code></pre></div><p>Now, experiment with different batch sizes. How does batch size affect:</p><ul><li>Convergence speed?</li><li>Final accuracy?</li><li>Computational efficiency?</li></ul><details><summary>Hint</summary><div>Smaller batch sizes (e.g., 32) introduce more noise into gradient estimates, which can help escape poor local minima but might make convergence erratic. Larger batch sizes (e.g., 256, 512) provide more stable gradients and faster computation per epoch but risk converging to sharper, less generalizable minima.</div></details><h3 id=5-support-vector-machines>5. Support Vector Machines
<a class=anchor href=#5-support-vector-machines>#</a></h3><p>Now we apply SVMs to the same problem using scikit-learn&rsquo;s optimized implementation. This serves as a powerful baseline to compare against our MLP. We use <code>GridSearchCV</code> to find the best hyperparameters.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>svm_model <span style=color:#f92672>=</span> SVC(kernel<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rbf&#39;</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>param_grid <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;C&#39;</span>: [<span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>], <span style=color:#e6db74>&#39;gamma&#39;</span>: [<span style=color:#e6db74>&#39;scale&#39;</span>, <span style=color:#e6db74>&#39;auto&#39;</span>, <span style=color:#ae81ff>0.01</span>]}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Use a subset for faster grid search</span>
</span></span><span style=display:flex><span>X_train_subset <span style=color:#f92672>=</span> X_train_scaled[:<span style=color:#ae81ff>5000</span>]
</span></span><span style=display:flex><span>y_train_subset <span style=color:#f92672>=</span> y_train[:<span style=color:#ae81ff>5000</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Starting Grid Search for SVM...&#34;</span>)
</span></span><span style=display:flex><span>start_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>grid_search <span style=color:#f92672>=</span> GridSearchCV(svm_model, param_grid, cv<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>, n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>grid_search<span style=color:#f92672>.</span>fit(X_train_subset, y_train_subset)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Grid search completed in </span><span style=color:#e6db74>{</span>time<span style=color:#f92672>.</span>time() <span style=color:#f92672>-</span> start_time<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> seconds&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>best_svm <span style=color:#f92672>=</span> grid_search<span style=color:#f92672>.</span>best_estimator_
</span></span><span style=display:flex><span>best_svm<span style=color:#f92672>.</span>fit(X_train_scaled, y_train)
</span></span><span style=display:flex><span>val_acc_svm <span style=color:#f92672>=</span> best_svm<span style=color:#f92672>.</span>score(X_val_scaled, y_val)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Best parameters: </span><span style=color:#e6db74>{</span>grid_search<span style=color:#f92672>.</span>best_params_<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Validation accuracy: </span><span style=color:#e6db74>{</span>val_acc_svm<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h3 id=6-comparative-analysis>6. Comparative Analysis
<a class=anchor href=#6-comparative-analysis>#</a></h3><p>Let&rsquo;s compare the performance of your custom MLP with the tuned SVM on the final test set.</p><p><strong>Task: Create an sklearn-compatible Estimator</strong></p><p>To easily compare your MLP with sklearn models, create a wrapper class <code>MLPClassifier</code> that inherits from <code>sklearn.base.BaseEstimator</code> and <code>sklearn.base.ClassifierMixin</code>.</p><ul><li>The <code>__init__</code> method should store hyperparameters like <code>learning_rate</code>, <code>epochs</code>, etc.</li><li>The <code>fit(self, X, y)</code> method should initialize and train your <code>MLPFromScratch</code> instance.</li><li>The <code>predict(self, X)</code> method should call the <code>predict</code> method of your trained MLP.</li><li>The <code>score(self, X, y)</code> method should predict on <code>X</code> and return the accuracy against <code>y</code>.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> classification_report, confusion_matrix
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># NOTE: This assumes you have created the MLPClassifier wrapper.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># mlp_sklearn = MLPClassifier(hidden_size=128, learning_rate=0.01, epochs=30)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># mlp_sklearn.fit(X_train_scaled, y_train)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Predictions on the test set</span>
</span></span><span style=display:flex><span><span style=color:#75715e># mlp_pred = mlp_sklearn.predict(X_test_scaled)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># svm_pred = best_svm.predict(X_test_scaled)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ...</span>
</span></span></code></pre></div><p>Analyze the computational costs.<details><summary>Hint</summary><div>Compare training time, prediction time, and memory usage. SVMs with RBF kernels have $O(n^2)$ training complexity, making them slow for large datasets. Neural networks have $O(n \cdot d \cdot h)$ complexity per epoch, which is more scalable.</div></details></p><h2 id=part-ii-deep-learning-with-cnns>Part II: Deep Learning with CNNs
<a class=anchor href=#part-ii-deep-learning-with-cnns>#</a></h2><h3 id=1-transition-to-pytorch>1. Transition to PyTorch
<a class=anchor href=#1-transition-to-pytorch>#</a></h3><p>We now move to PyTorch for implementing Convolutional Neural Networks (CNNs). PyTorch provides automatic differentiation and GPU acceleration, which are essential for deep learning. The following boilerplate code prepares the data for PyTorch.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.optim <span style=color:#66d9ef>as</span> optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> DataLoader, TensorDataset
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn.functional <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Using device: </span><span style=color:#e6db74>{</span>device<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Convert numpy arrays to PyTorch tensors and reshape for CNNs (N, C, H, W)</span>
</span></span><span style=display:flex><span>X_train_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>FloatTensor(X_train_scaled<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>y_train_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>LongTensor(y_train)
</span></span><span style=display:flex><span>X_val_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>FloatTensor(X_val_scaled<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>y_val_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>LongTensor(y_val)
</span></span><span style=display:flex><span>X_test_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>FloatTensor(X_test_scaled<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>y_test_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>LongTensor(y_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_dataset <span style=color:#f92672>=</span> TensorDataset(X_train_tensor, y_train_tensor)
</span></span><span style=display:flex><span>val_dataset <span style=color:#f92672>=</span> TensorDataset(X_val_tensor, y_val_tensor)
</span></span><span style=display:flex><span>test_dataset <span style=color:#f92672>=</span> TensorDataset(X_test_tensor, y_test_tensor)
</span></span><span style=display:flex><span>train_loader <span style=color:#f92672>=</span> DataLoader(train_dataset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>val_loader <span style=color:#f92672>=</span> DataLoader(val_dataset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>test_loader <span style=color:#f92672>=</span> DataLoader(test_dataset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span></code></pre></div><h3 id=2-convolutional-neural-network-design>2. Convolutional Neural Network Design
<a class=anchor href=#2-convolutional-neural-network-design>#</a></h3><p>CNNs exploit the spatial structure of images through local connectivity and parameter sharing.</p><h4 id=cnn-architecture-implementation>CNN Architecture Implementation
<a class=anchor href=#cnn-architecture-implementation>#</a></h4><p><strong>Task: Implement a Simple CNN in PyTorch</strong></p><p>Create a <code>SimpleCNN</code> class that inherits from <code>nn.Module</code>.</p><ol><li><p><strong><code>__init__(self)</code></strong>:</p><ul><li>Define the layers of the network. Use the following architecture:<ol><li><code>nn.Conv2d</code>: 1 input channel, 32 output channels, kernel size of 3, padding of 1.</li><li><code>nn.MaxPool2d</code>: kernel size of 2, stride of 2. (This will reduce 28x28 to 14x14).</li><li><code>nn.Conv2d</code>: 32 input channels, 64 output channels, kernel size of 3, padding of 1.</li><li><code>nn.MaxPool2d</code>: kernel size of 2, stride of 2. (This will reduce 14x14 to 7x7).</li><li><code>nn.Linear</code>: Input size will be the flattened output of the previous layer (<code>64 * 7 * 7</code>). Output size of 128.</li><li><code>nn.Dropout</code>: with a probability of 0.5 for regularization.</li><li><code>nn.Linear</code>: 128 inputs, 10 outputs (for the 10 digit classes).</li></ol></li></ul></li><li><p><strong><code>forward(self, x)</code></strong>:</p><ul><li>Define the data flow through the network.</li><li>Pass the input <code>x</code> through <code>conv1</code>, then apply a <code>F.relu</code> activation, then pass through the first <code>pool</code> layer.</li><li>Repeat for the second convolutional block (<code>conv2</code>, <code>relu</code>, <code>pool</code>).</li><li>Before the fully connected layers, you must flatten the tensor. Use <code>x = x.view(-1, 64 * 7 * 7)</code>.</li><li>Pass the flattened tensor through <code>fc1</code>, <code>relu</code>, <code>dropout</code>, and finally <code>fc2</code>.</li><li>Return the raw output scores (logits) from <code>fc2</code>. The loss function will handle the softmax.</li></ul></li></ol><h3 id=3-training-methodology>3. Training Methodology
<a class=anchor href=#3-training-methodology>#</a></h3><h4 id=training-loop-implementation>Training Loop Implementation
<a class=anchor href=#training-loop-implementation>#</a></h4><p><strong>Task: Implement a PyTorch Training Loop</strong></p><p>Write a function <code>train_model(model, train_loader, val_loader, ...)</code> that trains your <code>SimpleCNN</code>.</p><ol><li><p><strong>Setup</strong>:</p><ul><li>Move the <code>model</code> to the selected <code>device</code>.</li><li>Define the <code>criterion</code> (loss function): <code>nn.CrossEntropyLoss()</code>.</li><li>Define the <code>optimizer</code>: <code>optim.Adam(model.parameters(), lr=...)</code>.</li></ul></li><li><p><strong>Outer Loop</strong>: Iterate through <code>epochs</code>.</p></li><li><p><strong>Training Phase (Inner Loop)</strong>:</p><ul><li>Set the model to training mode: <code>model.train()</code>.</li><li>Iterate through the <code>train_loader</code> to get batches of <code>data</code> and <code>target</code>.</li><li>Move <code>data</code> and <code>target</code> to the <code>device</code>.</li><li><strong>Crucially, zero the gradients</strong>: <code>optimizer.zero_grad()</code>.</li><li>Perform a forward pass: <code>output = model(data)</code>.</li><li>Calculate the loss: <code>loss = criterion(output, target)</code>.</li><li>Perform backpropagation: <code>loss.backward()</code>.</li><li>Update the model weights: <code>optimizer.step()</code>.</li><li>Keep track of running loss and accuracy.</li></ul></li><li><p><strong>Validation Phase (Inner Loop)</strong>:</p><ul><li>Set the model to evaluation mode: <code>model.eval()</code>.</li><li><strong>Disable gradient calculation</strong> with <code>with torch.no_grad():</code>.</li><li>Iterate through the <code>val_loader</code>.</li><li>Calculate the validation loss and accuracy for the epoch.</li></ul></li><li><p><strong>Logging & Return</strong>:</p><ul><li>Print the training and validation statistics at the end of each epoch.</li><li>Return a history dictionary containing lists of training losses, validation losses, etc., for later plotting.</li></ul></li></ol><h3 id=4-advanced-optimization-strategies>4. Advanced Optimization Strategies
<a class=anchor href=#4-advanced-optimization-strategies>#</a></h3><h4 id=comparing-optimizers>Comparing Optimizers
<a class=anchor href=#comparing-optimizers>#</a></h4><p><strong>Task: Compare Optimizers</strong></p><p>Adapt your training loop into a new function, <code>compare_optimizers</code>. This function should:</p><ol><li>Take the model class as an argument.</li><li>Have a dictionary of optimizers to test (e.g., <code>'SGD': optim.SGD</code>, <code>'Adam': optim.Adam</code>).</li><li>Loop through this dictionary. In each iteration:<ul><li>Instantiate a new model and the corresponding optimizer.</li><li>Run the training for a fixed number of epochs.</li><li>Store the validation accuracy history for each optimizer.</li></ul></li><li>Return a dictionary of results.
Finally, plot the validation accuracy curves for all optimizers on a single graph to compare their convergence behavior.</li></ol><h4 id=learning-rate-scheduling>Learning Rate Scheduling
<a class=anchor href=#learning-rate-scheduling>#</a></h4><p><strong>Task: Implement Learning Rate Scheduling</strong></p><p>Modify your training function to include a learning rate scheduler.</p><ol><li>After defining the optimizer, create a scheduler instance: <code>scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)</code>. This scheduler reduces the LR when the validation loss (<code>'min'</code>) stops improving for 3 (<code>patience</code>) epochs.</li><li>At the end of each epoch, after the validation loop, call the scheduler&rsquo;s step function with the current validation loss: <code>scheduler.step(val_loss)</code>.</li><li>Log the learning rate at each epoch to see how it changes over time. You can get it from <code>optimizer.param_groups[0]['lr']</code>.</li><li>Plot the loss curves and the learning rate over epochs.</li></ol><h2 id=part-iii-transfer-learning-with-fashion-mnist>Part III: Transfer Learning with Fashion-MNIST
<a class=anchor href=#part-iii-transfer-learning-with-fashion-mnist>#</a></h2><h3 id=1-fashion-mnist-introduction>1. Fashion-MNIST Introduction
<a class=anchor href=#1-fashion-mnist-introduction>#</a></h3><p>Fashion-MNIST is a drop-in replacement for MNIST but is more challenging. We will use it to demonstrate the power of transfer learning.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([transforms<span style=color:#f92672>.</span>ToTensor(), transforms<span style=color:#f92672>.</span>Normalize((<span style=color:#ae81ff>0.5</span>,), (<span style=color:#ae81ff>0.5</span>,))])
</span></span><span style=display:flex><span>fashion_train <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>FashionMNIST(<span style=color:#e6db74>&#39;./data&#39;</span>, train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, transform<span style=color:#f92672>=</span>transform)
</span></span><span style=display:flex><span>fashion_test <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>FashionMNIST(<span style=color:#e6db74>&#39;./data&#39;</span>, train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, transform<span style=color:#f92672>=</span>transform)
</span></span><span style=display:flex><span>fashion_train_loader <span style=color:#f92672>=</span> DataLoader(fashion_train, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>fashion_test_loader <span style=color:#f92672>=</span> DataLoader(fashion_test, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span></code></pre></div><h3 id=2-practical-implementation>2. Practical Implementation
<a class=anchor href=#2-practical-implementation>#</a></h3><p>We will adapt a model pre-trained on ImageNet for our grayscale clothing classification task.</p><p><strong>Task: Implement a Transfer Learning Model</strong></p><p>Your goal is to build, train, and fine-tune a transfer learning model.</p><ol><li>Model Definition"</li></ol><p>Create a <code>TransferLearningModel</code> class that inherits from <code>nn.Module</code>.</p><ul><li><strong><code>__init__(self)</code></strong>:<ul><li>Load a pre-trained model from <code>torchvision.models</code>, for example, <code>models.mobilenet_v2(pretrained=True)</code>.</li><li><strong>Freeze the backbone</strong>: Iterate through the parameters of the loaded model (<code>self.model.parameters()</code>) and set <code>param.requires_grad = False</code>. This prevents them from being updated during training.</li><li><strong>Handle channel mismatch</strong>: Fashion-MNIST is grayscale (1 channel), but MobileNetV2 expects RGB (3 channels). Add a <code>nn.Conv2d(1, 3, kernel_size=1)</code> layer to convert the input.</li><li><strong>Replace the classifier</strong>: The final layer of the pre-trained model must be replaced with a new one suited for our 10-class problem. For MobileNetV2, this is <code>self.model.classifier</code>. Replace it with a <code>nn.Linear</code> layer with the correct number of input features (1280 for MobileNetV2) and 10 output features.</li></ul></li><li><strong><code>forward(self, x)</code></strong>:<ul><li>First, pass the input <code>x</code> through your 1-to-3 channel conversion layer.</li><li>Then, pass the result through the main pre-trained model.</li></ul></li></ul><ol start=2><li>Stage 1: Feature Extraction
Train the model with the frozen backbone. This means you are only training the new classifier layer you added.</li></ol><ul><li>Write a training loop for this stage.</li><li><strong>Important</strong>: The optimizer should only be passed the parameters that have <code>requires_grad</code> set to true. Use <code>optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)</code>.</li><li>Train for a few epochs (e.g., 5) with a standard learning rate like <code>0.001</code>.</li></ul><ol start=3><li>Stage 2: Fine-Tuning
After the initial training, unfreeze some of the later layers of the pre-trained model to adapt them to the new dataset.</li></ol><ul><li>Add a method <code>unfreeze_layers(self, num_layers)</code> to your model class. It should set <code>requires_grad = True</code> for the parameters of the last <code>num_layers</code> of the feature extractor (<code>self.model.features</code>).</li><li>Call this method to unfreeze the last few layers (e.g., <code>model.unfreeze_layers(3)</code>).</li><li>Train the model again for a few more epochs.</li><li><strong>Crucially</strong>, use a much <strong>lower learning rate</strong> (e.g., <code>1e-4</code>) to avoid corrupting the pre-trained weights.</li></ul><h3 id=4-comparative-analysis>4. Comparative Analysis
<a class=anchor href=#4-comparative-analysis>#</a></h3><p>Finally, train your <code>SimpleCNN</code> from scratch on Fashion-MNIST and compare its test accuracy curve against your two-stage transfer learning model. Also, consider the difference in training time.</p><h3 id=exercises-for-further-practice>Exercises for Further Practice
<a class=anchor href=#exercises-for-further-practice>#</a></h3><ol><li>Implement data augmentation (<code>torchvision.transforms</code>) for the CNN and measure its impact on generalization.</li><li>Try different CNN architectures (e.g., add more layers, use different filter sizes).</li><li>Implement early stopping in your training loop based on validation performance.</li><li>Explore other pre-trained models (ResNet, EfficientNet) for transfer learning.</li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#learning-objectives>Learning objectives</a></li><li><a href=#part-i-classical-machine-learning-approaches>Part I: Classical Machine Learning Approaches</a><ul><li><a href=#1-introduction-and-data-exploration>1. Introduction and Data Exploration</a></li><li><a href=#2-data-preprocessing-and-visualization>2. Data Preprocessing and Visualization</a></li><li><a href=#3-experimental-methodology>3. Experimental Methodology</a></li><li><a href=#4-multi-layer-perceptron-from-scratch>4. Multi-Layer Perceptron from Scratch</a></li><li><a href=#5-support-vector-machines>5. Support Vector Machines</a></li><li><a href=#6-comparative-analysis>6. Comparative Analysis</a></li></ul></li><li><a href=#part-ii-deep-learning-with-cnns>Part II: Deep Learning with CNNs</a><ul><li><a href=#1-transition-to-pytorch>1. Transition to PyTorch</a></li><li><a href=#2-convolutional-neural-network-design>2. Convolutional Neural Network Design</a></li><li><a href=#3-training-methodology>3. Training Methodology</a></li><li><a href=#4-advanced-optimization-strategies>4. Advanced Optimization Strategies</a></li></ul></li><li><a href=#part-iii-transfer-learning-with-fashion-mnist>Part III: Transfer Learning with Fashion-MNIST</a><ul><li><a href=#1-fashion-mnist-introduction>1. Fashion-MNIST Introduction</a></li><li><a href=#2-practical-implementation>2. Practical Implementation</a></li><li><a href=#4-comparative-analysis>4. Comparative Analysis</a></li><li><a href=#exercises-for-further-practice>Exercises for Further Practice</a></li></ul></li></ul></nav></div></aside></main></body></html>